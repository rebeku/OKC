{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import textacy\n",
    "import spacy\n",
    "spacy.load('en')\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "okc = pd.read_csv('../Assets/A/profiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59946, 31)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay = pd.read_csv('../Assets/A/one_long_essay.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57809, 23)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     about me i would love to think that i was some...\n",
       "1     i am a chef this is what that means i am a wor...\n",
       "2     i m not ashamed of much but writing public tex...\n",
       "3     i work in a library and go to school reading t...\n",
       "4     hey how s it going currently vague on the prof...\n",
       "5     i m an australian living in san francisco but ...\n",
       "6     life is about the little things i love to laug...\n",
       "7     writing meeting new people spending time with ...\n",
       "8     oh goodness at the moment i have jobs so it d ...\n",
       "9     my names jake i m a creative guy and i look fo...\n",
       "10    update i m seeing someone so off the market i ...\n",
       "11    i was born in wisconsin grew up in iowa and mo...\n",
       "12                                    bang my shit bang\n",
       "13    i have an awesome career working as a senior m...\n",
       "14    dancing playing exploring smiling and doing my...\n",
       "15    i just moved to the bay area from austin tx or...\n",
       "16    to sum myself in whole i have adventurous tend...\n",
       "17    some of my favorite things riding my motorcycl...\n",
       "18    i relocated to san francisco half a year ago t...\n",
       "19    i grew up in a small town in the midwest and h...\n",
       "20    my name is ashley and i live in san francisco ...\n",
       "21    i tend to think the same way a comedian does a...\n",
       "22    here s a completely fake summary i wrote while...\n",
       "23    bay area transplant six years or so now straig...\n",
       "24    hey to all hope all is well and your having a ...\n",
       "25    full time student full time square i change fr...\n",
       "26    i suck at these things but here it goes i m a ...\n",
       "27    i moved here recently and love this place i m ...\n",
       "28    i m told i can get along with anyone a product...\n",
       "29    iiiiiiiiiiiiiiiiii i hate talking about myself...\n",
       "30    to life love and loot i like smart funny and s...\n",
       "31    much more to add but this is a start i am a mi...\n",
       "32    apparently has become a new favorite word of m...\n",
       "33    i grew up near sacramento moved to sf for scho...\n",
       "34                    new here coming soon underwriting\n",
       "35    i lost a needle in a haystack once and found i...\n",
       "36    let s go to a festival and dance all night run...\n",
       "37    why hello there i m entertaining the thought t...\n",
       "38    i love life oh okcupid is telling me that thre...\n",
       "39    i am new to the san francisco bay area and loo...\n",
       "40    i grew up in new york and san diego half and h...\n",
       "41    i m an optimist with a healthy sense of impend...\n",
       "42    i don t really like summarizing myself but who...\n",
       "43    i am an east coast transplant looking for fun ...\n",
       "44    born in the philippines grew up in a small tow...\n",
       "45    born varberg sweden knew how to say strawberry...\n",
       "46    i m an east coast transplant that s lived in s...\n",
       "47    i love it here except when it s hotter than a ...\n",
       "48    concerts running hanging out with friends and ...\n",
       "49    i m going to start right off breaking into son...\n",
       "Name: essays, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay.essays.iloc[:50,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "essay = essay.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rerun feature processing on train.csv!!!! ASAP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>height</th>\n",
       "      <th>income</th>\n",
       "      <th>job</th>\n",
       "      <th>...</th>\n",
       "      <th>offspring</th>\n",
       "      <th>orientation</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>status</th>\n",
       "      <th>essays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>asian, white</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>transportation</td>\n",
       "      <td>...</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism and very serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "      <td>about me i would love to think that i was some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>white</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80000</td>\n",
       "      <td>hospitality / travel</td>\n",
       "      <td>...</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly), french (...</td>\n",
       "      <td>single</td>\n",
       "      <td>i am a chef this is what that means i am a wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>has cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english, french, c++</td>\n",
       "      <td>available</td>\n",
       "      <td>i m not ashamed of much but writing public tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>white</td>\n",
       "      <td>71.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>student</td>\n",
       "      <td>...</td>\n",
       "      <td>doesn&amp;rsquo;t want kids</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces</td>\n",
       "      <td>no</td>\n",
       "      <td>english, german (poorly)</td>\n",
       "      <td>single</td>\n",
       "      <td>i work in a library and go to school reading t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>asian, black, other</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>artistic / musical / writer</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>aquarius</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "      <td>hey how s it going currently vague on the prof...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age       body_type               diet    drinks      drugs  \\\n",
       "0   22  a little extra  strictly anything  socially      never   \n",
       "1   35         average       mostly other     often  sometimes   \n",
       "2   38            thin           anything  socially        NaN   \n",
       "3   23            thin         vegetarian  socially        NaN   \n",
       "4   29        athletic                NaN  socially      never   \n",
       "\n",
       "                           education            ethnicity  height  income  \\\n",
       "0      working on college/university         asian, white    75.0      -1   \n",
       "1              working on space camp                white    70.0   80000   \n",
       "2     graduated from masters program                  NaN    68.0      -1   \n",
       "3      working on college/university                white    71.0   20000   \n",
       "4  graduated from college/university  asian, black, other    66.0      -1   \n",
       "\n",
       "                           job  \\\n",
       "0               transportation   \n",
       "1         hospitality / travel   \n",
       "2                          NaN   \n",
       "3                      student   \n",
       "4  artistic / musical / writer   \n",
       "\n",
       "                         ...                          \\\n",
       "0                        ...                           \n",
       "1                        ...                           \n",
       "2                        ...                           \n",
       "3                        ...                           \n",
       "4                        ...                           \n",
       "\n",
       "                                      offspring orientation  \\\n",
       "0  doesn&rsquo;t have kids, but might want them    straight   \n",
       "1  doesn&rsquo;t have kids, but might want them    straight   \n",
       "2                                           NaN    straight   \n",
       "3                       doesn&rsquo;t want kids    straight   \n",
       "4                                           NaN    straight   \n",
       "\n",
       "                        pets                                  religion sex  \\\n",
       "0  likes dogs and likes cats     agnosticism and very serious about it   m   \n",
       "1  likes dogs and likes cats  agnosticism but not too serious about it   m   \n",
       "2                   has cats                                       NaN   m   \n",
       "3                 likes cats                                       NaN   m   \n",
       "4  likes dogs and likes cats                                       NaN   m   \n",
       "\n",
       "                                 sign     smokes  \\\n",
       "0                              gemini  sometimes   \n",
       "1                              cancer         no   \n",
       "2  pisces but it doesn&rsquo;t matter         no   \n",
       "3                              pisces         no   \n",
       "4                            aquarius         no   \n",
       "\n",
       "                                              speaks     status  \\\n",
       "0                                            english     single   \n",
       "1  english (fluently), spanish (poorly), french (...     single   \n",
       "2                               english, french, c++  available   \n",
       "3                           english, german (poorly)     single   \n",
       "4                                            english     single   \n",
       "\n",
       "                                              essays  \n",
       "0  about me i would love to think that i was some...  \n",
       "1  i am a chef this is what that means i am a wor...  \n",
       "2  i m not ashamed of much but writing public tex...  \n",
       "3  i work in a library and go to school reading t...  \n",
       "4  hey how s it going currently vague on the prof...  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'age', u'body_type', u'diet', u'drinks', u'drugs', u'education',\n",
       "       u'ethnicity', u'height', u'income', u'job', u'last_online', u'location',\n",
       "       u'offspring', u'orientation', u'pets', u'religion', u'sex', u'sign',\n",
       "       u'smokes', u'speaks', u'status', u'essays'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Change essays column to unicode\n",
    "\n",
    "def decode(essay):\n",
    "    return essay.decode('utf-8')\n",
    "\n",
    "essay['essays'] = essay.essays.apply(decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "essay_d = essay.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(essay_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save text as content_stream, holding onto other info as metadata\n",
    "content_stream, metadata_stream = textacy.fileio.split_content_and_metadata(essay_d, 'essays', itemwise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = textacy.TextCorpus.from_texts('en', content_stream, metadata_stream, n_threads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_term_matrix, id2term = corpus.as_doc_term_matrix(\n",
    "    (doc.as_terms_list(words=True, ngrams=False, named_entities=True)\n",
    "     for doc in corpus),\n",
    "    weighting='tfidf', normalize=True, smooth_idf=True, min_df=2, max_df=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = textacy.tm.TopicModel('nmf', n_topics=10)\n",
    "model.fit(doc_term_matrix)\n",
    "doc_topic_matrix = model.transform(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Textacy Topic Model on Full Essay Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('topic', 0, ':', u'm   t   like   thing   think   people   ve   time   good   know')\n",
      "('topic', 1, ':', u'love   life   enjoy   friend   laugh   travel   great   smile   good   live')\n",
      "('topic', 2, ':', u'be   not   lol   u   know   n   can   good   ill   money')\n",
      "('topic', 3, ':', u'art   music   artist   design   creative   film   draw   photography   painting   gallery')\n",
      "('topic', 4, ':', u'facebook   com   www   inspiring   design   profile   delete   piercings   reddit   kinky')\n",
      "('topic', 5, ':', u'fun   look   like   have   meet   work   want   guy   friend   go')\n",
      "('topic', 6, ':', u'year   work   san   francisco   travel   city   live   bay   sf   friend')\n",
      "('topic', 7, ':', u'movie   friend   food   family   music   love   favorite   like   hang   watch')\n",
      "('topic', 8, ':', u'new   try   thing   meet   people   want   restaurant   explore   friend   interesting')\n",
      "('topic', 9, ':', u'youtube   com   http   www   v   watch   video   feature   av   ob')\n"
     ]
    }
   ],
   "source": [
    "for topic_idx, top_terms in model.top_topic_terms(id2term, top_n=10):\n",
    "    print('topic', topic_idx, ':', '   '.join(top_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('topic', 0, ':', u't   thing   m   like   people   think   time   s   good   know')\n",
      "('topic', 1, ':', u'be   not   lol   u   know   good   n   guy   go   money')\n",
      "('topic', 2, ':', u'm   ve   ll   pretty   t   look   guy   d   go   sure')\n",
      "('topic', 3, ':', u'love   laugh   music   favorite   movie   food   smile   cook   life   family')\n",
      "('topic', 4, ':', u'schrute   sicily   auburn   spaniard   unsettling   license   admin   about month   tmnt   kingpin')\n",
      "('topic', 5, ':', u'art   music   artist   design   creative   photography   draw   film   painting   gallery')\n",
      "('topic', 6, ':', u'dance   salsa   music   dancing   hip   hop   swing   tango   party   food')\n",
      "('topic', 7, ':', u'friend   new   work   family   travel   try   enjoy   go   fun   food')\n",
      "('topic', 8, ':', u'youtube   com   http   www   v   watch   feature   video   facebook   av')\n",
      "('topic', 9, ':', u'like   fun   movie   good   food   kind   music   thing   watch   go')\n",
      "('topic', 10, ':', u'game   video   play   movie   throne   board   series   watch   anime   hang')\n",
      "('topic', 11, ':', u'bike   rid   ride   mountain   motorcycle   bicycle   run   road   hike   beer')\n",
      "('topic', 12, ':', u'life   enjoy   look   relationship   share   woman   great   good   person   fun')\n",
      "('topic', 13, ':', u'schrute   sicily   auburn   spaniard   unsettling   license   admin   about month   tmnt   kingpin')\n",
      "('topic', 14, ':', u'hair   makeup   salon   make   dog   curly   styling   stylist   not   friend')\n"
     ]
    }
   ],
   "source": [
    "model = textacy.tm.TopicModel('nmf', n_topics=15)\n",
    "model.fit(doc_term_matrix)\n",
    "doc_topic_matrix = model.transform(doc_term_matrix)\n",
    "for topic_idx, top_terms in model.top_topic_terms(id2term, top_n=10):\n",
    "    print('topic', topic_idx, ':', '   '.join(top_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('topic', 0, ':', u'm   like   love   t   friend   good   thing   time   people   work')\n",
      "('topic', 1, ':', u'be   not   lol   u   love   like   fun   good   work   go')\n",
      "('topic', 2, ':', u'youtube   com   http   www   v   watch   video   feature   facebook   av')\n"
     ]
    }
   ],
   "source": [
    "model = textacy.tm.TopicModel('nmf', n_topics=3)\n",
    "model.fit(doc_term_matrix)\n",
    "doc_topic_matrix = model.transform(doc_term_matrix)\n",
    "for topic_idx, top_terms in model.top_topic_terms(id2term, top_n=10):\n",
    "    print('topic', topic_idx, ':', '   '.join(top_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## REFINE THIS FUNCTION\n",
    "def find_topics(condition1, condition2, n_topics=10, top_n=10, max_df=.95):\n",
    "    filtered_corpus = list(corpus.get_docs(\n",
    "            lambda doc: doc.metadata[condition1] == condition2))\n",
    "    # Build dtm from filtered corpus\n",
    "    doc_term_matrix, id2term = corpus.as_doc_term_matrix(\n",
    "    (doc.as_terms_list(words=True, ngrams=False, named_entities=True)\n",
    "     for doc in filtered_corpus),\n",
    "    weighting='tfidf', normalize=True, smooth_idf=True, min_df=2, max_df=max_df)\n",
    "    # Fit topic model\n",
    "    model = textacy.tm.TopicModel('nmf', n_topics=n_topics)\n",
    "    model.fit(doc_term_matrix)\n",
    "    doc_topic_matrix = model.transform(doc_term_matrix)\n",
    "    for topic_idx, top_terms in model.top_topic_terms(id2term, top_n=top_n):\n",
    "        print('topic', topic_idx, ':', '   '.join(top_terms))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run topic model just on essays by men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('topic', 0, ':', u'm   like   t   thing   good   time   people   think   love   ve')\n",
      "('topic', 1, ':', u'be   not   u   like   ill   n   good   know   alot   can')\n",
      "('topic', 2, ':', u'youtube   com   www   http   v   watch   facebook   feature   ob   av')\n",
      "('topic', 3, ':', u'new   meet   try   explore   bay   city   thing   people   san   area')\n",
      "('topic', 4, ':', u'friend   love   family   work   food   movie   music   good   sport   life')\n",
      "('topic', 5, ':', u'money   goin   make   drum   cool   nd   car   retire   want   current')\n",
      "('topic', 6, ':', u'woman   sex   want   relationship   man   treat   love   mature   honest   share')\n",
      "('topic', 7, ':', u'fun   have   like   meet   want   sex   mind   open   funny   work')\n",
      "('topic', 8, ':', u'look   enjoy   guy   relationship   live   real   smile   girl   good   share')\n",
      "('topic', 9, ':', u'lol   soccer   haha   not   guy   know   nice   lazy   phone   ask')\n"
     ]
    }
   ],
   "source": [
    "find_topics('sex','m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... And just by women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('topic', 0, ':', u'like   friend   good   t   love   thing   time   people   work   music')\n",
      "('topic', 1, ':', u'm   t   ve   pretty   ll   d   think   game   right   lot')\n",
      "('topic', 2, ':', u'be   not   school   can   hey   son   go   look   wanna   know')\n",
      "('topic', 3, ':', u'u   n   wana   daughter   tell   kno   jus   chihuahua   beverly   know')\n",
      "('topic', 4, ':', u'shiny   bright   go   sheep   laze   one year   warning   conversate   pass   display')\n",
      "('topic', 5, ':', u'lol   phone   future   time   bourne   favorite   relax   starbucks   know   movie')\n",
      "('topic', 6, ':', u'dance   salsa   music   dancing   tango   hip   hop   swing   latin   study')\n",
      "('topic', 7, ':', u'brasil   requirement   laze   one year   warning   conversate   pass   display   flag   african')\n",
      "('topic', 8, ':', u'love   life   smile   family   friend   travel   full   live   fun   enjoy')\n",
      "('topic', 9, ':', u'brasil   requirement   laze   one year   warning   conversate   pass   display   flag   african')\n"
     ]
    }
   ],
   "source": [
    "find_topics('sex','f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why the repeated topic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('topic', 0, ':', u'like   thing   love   people   m   good   music   food   movie   time')\n",
      "('topic', 1, ':', u'm   ve   pretty   ll   game   d   right   t   time   try')\n",
      "('topic', 2, ':', u'love   life   smile   music   live   eye   heart   cook   family   dance')\n",
      "('topic', 3, ':', u'be   u   school   hey   son   n   not   look   wanna   go')\n",
      "('topic', 4, ':', u'brasil   requirement   laze   one year   warning   conversate   pass   display   flag   african')\n",
      "('topic', 5, ':', u'brasil   requirement   laze   one year   warning   conversate   pass   display   flag   african')\n",
      "('topic', 6, ':', u't   like   haven   know   profile   think   message   win   isn   time')\n",
      "('topic', 7, ':', u'brasil   requirement   laze   one year   warning   conversate   pass   display   flag   african')\n",
      "('topic', 8, ':', u'art   music   creative   artist   photography   gallery   create   paint   adventure   theater')\n",
      "('topic', 9, ':', u'brasil   requirement   laze   one year   warning   conversate   pass   display   flag   african')\n",
      "('topic', 10, ':', u'not   can   wo   know   fun   girl   school   talk   want   secret')\n",
      "('topic', 11, ':', u'full   regret   mind   instructor   live   spirited   enjoy   life   london   yoga')\n",
      "('topic', 12, ':', u'brasil   requirement   laze   one year   warning   conversate   pass   display   flag   african')\n",
      "('topic', 13, ':', u'lol   phone   future   time   bourne   favorite   relax   movie   starbucks   u')\n",
      "('topic', 14, ':', u'brasil   requirement   laze   one year   warning   conversate   pass   display   flag   african')\n",
      "('topic', 15, ':', u'brasil   requirement   laze   one year   warning   conversate   pass   display   flag   african')\n",
      "('topic', 16, ':', u'friend   enjoy   family   new   travel   try   good   fun   time   work')\n",
      "('topic', 17, ':', u'brasil   requirement   laze   one year   warning   conversate   pass   display   flag   african')\n",
      "('topic', 18, ':', u'design   fashion   interior   graphic   designer   graduate   fran   summer   sewing   roommate')\n",
      "('topic', 19, ':', u'bacon   decision   eat   b   alcohol   bad   meat   tech   sleeveless   turtleneck')\n"
     ]
    }
   ],
   "source": [
    "find_topics('sex','f', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why does this repeat the same phrase so many times?\n",
    "u'brasil   requirement   laze   one year   warning   conversate   pass   display   flag   african   mindless   moderately   sheep   pow   forbid'\n",
    "\n",
    "Is there a repeated essay in essays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_bad_string(essay):\n",
    "    if essay.find('conversate') >= 0:\n",
    "        print essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "essay.essays.apply(find_bad_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How about people who drink a lot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "drunk_essays = list(corpus.get_docs(\n",
    "            lambda doc: doc.metadata['drinks'] == 'desperately' or doc.metadata['drinks'] == 'very often'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(drunk_essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('topic', 0, ':', u'm   like   t   think   good   time   thing   music   love   work   life   people   food   movie   book')\n",
      "('topic', 1, ':', u'youtube   com   http   www   v   watch   facebook   netflix   job   capable   beatles   state   improve   c   store')\n",
      "('topic', 2, ':', u'n   wanna   bring   city   bike   party   guy   friend   livin   gal   brew   whiskey   wild   dude   da')\n",
      "('topic', 3, ':', u'yahoo   notebook   com   play   coffee   family   want   love   friend   movie   music   simply   table   point   jack')\n",
      "('topic', 4, ':', u'hair   salon   intern   pepper   dr   blow   rap   love   different   animal   interested   dance   girl   school   fun')\n",
      "('topic', 5, ':', u'cheeseburger   double   t   gotta   pickle   color   tomato   chick   fat   burger   king   beef   clean   cheese   movie')\n",
      "('topic', 6, ':', u'amateur   advice   answer   avoid   high   musical   musician   jam   reason   be   sport   conversation   message   hard   grow')\n",
      "('topic', 7, ':', u'foreign   wit   noir   theater   reader   irreverent   m   shoot   fan   fiction   dinner   culture   non   humor   country')\n",
      "('topic', 8, ':', u'zombie   apocalypse   not   be   google   fantasy   nerdy   wine   meat   love   general   video   people   party   need')\n",
      "('topic', 9, ':', u'be   money   lot   lol   da   wit   car   blood   want   day   sum   dat   freak   lil   u')\n"
     ]
    }
   ],
   "source": [
    "doc_term_matrix, id2term = corpus.as_doc_term_matrix(\n",
    "    (doc.as_terms_list(words=True, ngrams=False, named_entities=True)\n",
    "     for doc in drunk_essays),\n",
    "    weighting='tfidf', normalize=True, smooth_idf=True, min_df=2, max_df=0.95)\n",
    "model = textacy.tm.TopicModel('nmf', n_topics=10)\n",
    "model.fit(doc_term_matrix)\n",
    "doc_topic_matrix = model.transform(doc_term_matrix)\n",
    "for topic_idx, top_terms in model.top_topic_terms(id2term, top_n=15):\n",
    "    print('topic', topic_idx, ':', '   '.join(top_terms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And people who don't drink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('topic', 0, ':', u'm   like   love   t   good   friend   thing   people   time   music')\n",
      "('topic', 1, ':', u'm   family   love   n   lil   minded   latin   hi   earth   new')\n",
      "('topic', 2, ':', u'be   not   box   work   random   school   bite   smoke   friendly   u')\n",
      "('topic', 3, ':', u'timey   abuse   kuti   karma   african   american   intimacy   software   earth   happiness')\n",
      "('topic', 4, ':', u'not   gym   soda   be   thing   can   candy   gear   dumb   bbq')\n",
      "('topic', 5, ':', u'marine   corp   ll   angeles   recruit   edible   ship   patrol   drill   seether')\n",
      "('topic', 6, ':', u'meditate   bread   meditation   swim   mission   classic   house   think   work   music')\n",
      "('topic', 7, ':', u'timey   abuse   kuti   karma   african   american   intimacy   software   earth   happiness')\n",
      "('topic', 8, ':', u'tom   tall   sixth   bass   band   stranger   die   meat   peeve   snl')\n",
      "('topic', 9, ':', u'jesus   bible   youtube   record   guitar   aa   church   bfa   narnia   dodgeball')\n"
     ]
    }
   ],
   "source": [
    "find_topics('drinks','not at all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore some job categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other                                742\n",
       "science / tech / engineering         520\n",
       "student                              513\n",
       "artistic / musical / writer          469\n",
       "computer / hardware / software       449\n",
       "sales / marketing / biz dev          438\n",
       "medicine / health                    419\n",
       "education / academia                 367\n",
       "executive / management               244\n",
       "entertainment / media                224\n",
       "banking / financial / real estate    214\n",
       "law / legal services                 123\n",
       "hospitality / travel                 114\n",
       "construction / craftsmanship         108\n",
       "clerical / administrative             66\n",
       "political / government                63\n",
       "rather not say                        36\n",
       "transportation                        35\n",
       "unemployed                            25\n",
       "retired                               25\n",
       "military                              17\n",
       "Name: job, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay.job.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('topic', 0, ':', u'm   like   love   t   friend   good   thing   work   time   new')\n",
      "('topic', 1, ':', u'spontaneous   concert   outdoors   adventure   run   hang   travel   family   friend   facto')\n",
      "('topic', 2, ':', u'youtube   http   v   www   com   watch   skinny   ha   chemistry   let')\n",
      "('topic', 3, ':', u'be   not   gonna   work   project   mind   fun   thing   friend   want')\n",
      "('topic', 4, ':', u'lobos   suck   mug   cuddle   literally   commercial   apartment   daughter   chivalry   permit')\n",
      "('topic', 5, ':', u'lobos   suck   mug   cuddle   literally   commercial   apartment   daughter   chivalry   permit')\n",
      "('topic', 6, ':', u'lobos   suck   mug   cuddle   literally   commercial   apartment   daughter   chivalry   permit')\n",
      "('topic', 7, ':', u'lobos   suck   mug   cuddle   literally   commercial   apartment   daughter   chivalry   permit')\n",
      "('topic', 8, ':', u'enjoy   look   live   lobos   commercial   apartment   daughter   chivalry   permit   merely')\n",
      "('topic', 9, ':', u'lobos   suck   mug   cuddle   literally   commercial   apartment   daughter   chivalry   permit')\n"
     ]
    }
   ],
   "source": [
    "find_topics('job', 'science / tech / engineering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('topic', 0, ':', u'm   like   love   t   people   time   friend   good   thing   music')\n",
      "('topic', 1, ':', u'be   not   u   good   know   wrestle   eyelash   highschool   friend   n')\n",
      "('topic', 2, ':', u'summer   interning   fran   graphic   year   roommate   design   degree   graduate   san')\n",
      "('topic', 3, ':', u'mac   cellphone   lunch   specific   discussion   hang   number   friend   wanna   reading')\n",
      "('topic', 4, ':', u'art   concept   game   school   draw   film   artist   gallery   video   painting')\n",
      "('topic', 5, ':', u'want   hang   talk   fun   new   friend   look   love   meet   marine')\n",
      "('topic', 6, ':', u'basketball   piano   school   go   fucking   weakerthans   rocket   bright   prince   previous')\n",
      "('topic', 7, ':', u'meet   student   one   favorite   new   people   thing   previous   pope   fit')\n",
      "('topic', 8, ':', u'flake   professor   concept   rocket   bright   prince   previous   pope   fit   scooter')\n",
      "('topic', 9, ':', u'lol   goin   haha   money   phone   sex   car   makin   smokin   flashy')\n"
     ]
    }
   ],
   "source": [
    "find_topics('job', 'student')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('topic', 0, ':', u'm   like   love   t   music   good   thing   people   friend   time')\n",
      "('topic', 1, ':', u'art   show   live   music   artist   illustration   owl   blanket   leon   weather')\n",
      "('topic', 2, ':', u'try   new   fun   design   sketch   grab   chillin   friend   owl   culture')\n",
      "('topic', 3, ':', u'bf   clumsy   muni   blanket   leon   weather   security   culture   bjrk   k')\n",
      "('topic', 4, ':', u'bf   clumsy   muni   blanket   leon   weather   security   culture   bjrk   k')\n",
      "('topic', 5, ':', u'facebook   design   www   com   hop   time   menswear   gladiator   gatsby   dedicated')\n",
      "('topic', 6, ':', u'bf   clumsy   muni   blanket   leon   weather   security   culture   bjrk   k')\n",
      "('topic', 7, ':', u'coffee   month   outside   think   louisiana   miami   airstream   ft   mutual   tight')\n",
      "('topic', 8, ':', u'bf   clumsy   muni   blanket   leon   weather   security   culture   bjrk   k')\n",
      "('topic', 9, ':', u'ballet   nose   diaper   beginner   natalie   convince   filthy   immortal   ticket   butt')\n"
     ]
    }
   ],
   "source": [
    "find_topics('job', 'artistic / musical / writer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('topic', 0, ':', u'm   like   t   love   thing   work   good   friend   people   time')\n",
      "('topic', 1, ':', u'sex   fun   russian   pant   bedroom   balance   rest   step   woman   eye')\n",
      "('topic', 2, ':', u'ray   man   exciting   good   fun   producer   murakami   borges   la   young')\n",
      "('topic', 3, ':', u'producer   charles   ros   hmmm   gamut   borges   la   young   th   cap')\n",
      "('topic', 4, ':', u'vacation   gotta   text   friendship   later   guitar   wine   hour   see   happy')\n",
      "('topic', 5, ':', u'producer   charles   ros   hmmm   gamut   borges   la   young   th   cap')\n",
      "('topic', 6, ':', u'dollar   morning   three   ancestor   flute   brace   dil   tofu   basil   two')\n",
      "('topic', 7, ':', u'nightclub   salsa   francisco   spend   san   restaurant   one year   bar   new   path')\n",
      "('topic', 8, ':', u'eccentric   hat   key   wear   funny   software   person   make   music   hesse')\n",
      "('topic', 9, ':', u'season   lose   rico   puerto   lost   girlfriend   dork   universe   follow   answer')\n"
     ]
    }
   ],
   "source": [
    "find_topics('job', 'computer / hardware / software')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('topic', 0, ':', u'm   love   like   friend   work   good   t   thing   time   people')\n",
      "('topic', 1, ':', u'love   life   spoil   dance   kid   raise   boob   gonna   sharp   preferably')\n",
      "('topic', 2, ':', u'personal   trainer   free   silent   crossfit   tame   hell   motivate   usual   suppose')\n",
      "('topic', 3, ':', u'm   like   lb   sexy   asian   nurse   guy   read   travel   insert')\n",
      "('topic', 4, ':', u'retreat   stunning   equal   gonna   sharp   preferably   reality   hot   freshly   digital')\n",
      "('topic', 5, ':', u'badminton   skate   physician   assistant   outgoing   lol   short   story   funny   long')\n",
      "('topic', 6, ':', u'lip   gloss   r   hip   type   b   reggaeton   lotion   m   mmm')\n",
      "('topic', 7, ':', u'be   not   medic   free   right   alot   school   business   n   med')\n",
      "('topic', 8, ':', u'looking   companionship   mystery   professional   medical   maybe   old   right   person   year')\n",
      "('topic', 9, ':', u'retreat   stunning   equal   gonna   sharp   preferably   reality   hot   freshly   digital')\n"
     ]
    }
   ],
   "source": [
    "find_topics('job', 'medicine / health')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore sexual orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "straight    5171\n",
       "gay          543\n",
       "bisexual     286\n",
       "Name: orientation, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay.orientation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('topic', 0, ':', u'm   t   like   thing   think   people   good   time   ve   know')\n",
      "('topic', 1, ':', u'be   not   know   good   can   money   ill   alot   want   school')\n",
      "('topic', 2, ':', u'u   n   sf   wana   kno   jus   eye   idk   like   school')\n",
      "('topic', 3, ':', u'youtube   com   www   http   v   watch   feature   video   av   ob')\n",
      "('topic', 4, ':', u'art   music   artist   creative   design   film   draw   painting   live   photography')\n",
      "('topic', 5, ':', u'mac   fleetwood   cheese   dre   da   vinci   somthing   style   code   wine')\n",
      "('topic', 6, ':', u'new   enjoy   friend   life   travel   fun   family   live   look   work')\n",
      "('topic', 7, ':', u'lol   soccer   not   guy   haha   know   phone   nice   laugh   people')\n",
      "('topic', 8, ':', u'friend   movie   like   food   family   music   hang   sport   work   favorite')\n",
      "('topic', 9, ':', u'love   life   dance   laugh   music   smile   favorite   family   eye   movie')\n"
     ]
    }
   ],
   "source": [
    "find_topics('orientation', 'straight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('topic', 0, ':', u'm   like   love   t   friend   good   people   time   work   life')\n",
      "('topic', 1, ':', u'be   not   chill   lol   love   u   ur   go   person   music')\n",
      "('topic', 2, ':', u'not   can   like   wo   hang   vegetarian   know   precious   baffle   nephew')\n",
      "('topic', 3, ':', u'arizona   dagger   barrel   shot   nephew   fear   impact   knowledge   pumpkin   alicia')\n",
      "('topic', 4, ':', u'arizona   dagger   barrel   shot   nephew   fear   impact   knowledge   pumpkin   alicia')\n",
      "('topic', 5, ':', u'francisco   san   maybe   look   new   m   friend   handsome   singer   native')\n",
      "('topic', 6, ':', u'arizona   dagger   barrel   shot   nephew   fear   impact   knowledge   pumpkin   alicia')\n",
      "('topic', 7, ':', u'arizona   dagger   barrel   shot   nephew   fear   impact   knowledge   pumpkin   alicia')\n",
      "('topic', 8, ':', u'ask   ll   question   blah   pale   nephew   fear   impact   knowledge   pumpkin')\n",
      "('topic', 9, ':', u'linux   rollerblade   addictive   babylon   quietness   yay   melodic   philadelphia   software   russian')\n"
     ]
    }
   ],
   "source": [
    "find_topics('orientation', 'gay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('topic', 0, ':', u'm   love   like   t   thing   people   time   friend   life   want')\n",
      "('topic', 1, ':', u'm   lb   asian   nurse   sexy   like   guy   travel   read   damned')\n",
      "('topic', 2, ':', u'damned   development   bjrk   k   burroughs   childhood   dancer   augusten   arcade   calm')\n",
      "('topic', 3, ':', u'be   n   not   digital   easy   lesson   differ   st   bmx   year')\n",
      "('topic', 4, ':', u'peanut   tree   give   type   m   listen   music   damned   childhood   dancer')\n",
      "('topic', 5, ':', u'photography   comedian   bjrk   k   burroughs   childhood   dancer   augusten   arcade   calm')\n",
      "('topic', 6, ':', u'damned   development   bjrk   k   burroughs   childhood   dancer   augusten   arcade   calm')\n",
      "('topic', 7, ':', u'tacos   idk   yummy   mouth   attend   r   school   m   damned   k')\n",
      "('topic', 8, ':', u'nothin   yeah   get   damned   comedian   k   burroughs   childhood   dancer   augusten')\n",
      "('topic', 9, ':', u'damned   development   bjrk   k   burroughs   childhood   dancer   augusten   arcade   calm')\n"
     ]
    }
   ],
   "source": [
    "find_topics('orientation', 'bisexual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore other lifestyle (smoking, drugs, diet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smokes requires custom condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no                4477\n",
       "sometimes          328\n",
       "when drinking      293\n",
       "yes                183\n",
       "trying to quit     155\n",
       "Name: smokes, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay.smokes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('topic', 0, ':', u'm   like   love   t   music   good   thing   people   time   life   food   friend   movie   work   think')\n",
      "('topic', 1, ':', u'be   not   lol   u   n   like   know   good   love   alot   life   go   guy   ill   ma')\n",
      "('topic', 2, ':', u'new   try   meet   explore   bay   restaurant   enjoy   thing   want   friend   soon   people   area   adventure   interesting')\n",
      "('topic', 3, ':', u'youtube   com   www   http   v   watch   feature   facebook   ob   video   bike   e   bfa   index   art')\n",
      "('topic', 4, ':', u'fun   work   friend   have   family   good   hang   play   hard   like   look   go   sport   want   lol')\n",
      "('topic', 5, ':', u'ask   tell   shall   receive   bubbly   tryna   hustle   ll   personality   know   son   question   gym   everthing   relaxation')\n",
      "('topic', 6, ':', u'admit   have   look   good   private   willing   proficient   sore   sigur   retire   being   goodbye   building   labrador   antoine')\n",
      "('topic', 7, ':', u'sore   youtu   disabled   retire   being   goodbye   building   sigur   antoine   labrador   homer   salinger   grunge   jonathan   partying')\n",
      "('topic', 8, ':', u'money   goin   drum   make   nd   dnt   retire   cool   easy   successful   car   play   lol   cuz   soon')\n",
      "('topic', 9, ':', u'sore   youtu   disabled   retire   being   goodbye   building   sigur   antoine   labrador   homer   salinger   grunge   jonathan   partying')\n"
     ]
    }
   ],
   "source": [
    "smokes_essays = list(corpus.get_docs(\n",
    "            lambda doc: doc.metadata['smokes'] != 'no'))\n",
    "# Build dtm\n",
    "doc_term_matrix, id2term = corpus.as_doc_term_matrix(\n",
    "    (doc.as_terms_list(words=True, ngrams=False, named_entities=True)\n",
    "     for doc in smokes_essays),\n",
    "    weighting='tfidf', normalize=True, smooth_idf=True, min_df=2, max_df=0.95)\n",
    "# Fit model\n",
    "model = textacy.tm.TopicModel('nmf', n_topics=10)\n",
    "model.fit(doc_term_matrix)\n",
    "doc_topic_matrix = model.transform(doc_term_matrix)\n",
    "for topic_idx, top_terms in model.top_topic_terms(id2term, top_n=15):\n",
    "    print('topic', topic_idx, ':', '   '.join(top_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "never        3746\n",
       "sometimes     782\n",
       "often          30\n",
       "Name: drugs, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay.drugs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('topic', 0, ':', u'm   like   love   t   thing   good   music   people   time   friend   work   food   life   movie   new')\n",
      "('topic', 1, ':', u'be   not   lol   n   love   u   ill   sport   chill   good   go   wanna   family   have   live')\n",
      "('topic', 2, ':', u'ashton   perspective   soggy   feed   crafty   camper   emotionally   breakfast   ultra   stalker   dirty   bitch   communication   tuck   teacher')\n",
      "('topic', 3, ':', u'ashton   perspective   soggy   feed   crafty   camper   emotionally   breakfast   ultra   stalker   dirty   bitch   communication   tuck   teacher')\n",
      "('topic', 4, ':', u'ashton   perspective   soggy   feed   crafty   camper   emotionally   breakfast   ultra   stalker   dirty   bitch   communication   tuck   teacher')\n",
      "('topic', 5, ':', u'funny   stuff   eccentric   person   research   software   hat   key   wear   guy   kind   fun   make   look   music')\n",
      "('topic', 6, ':', u'youtube   www   v   http   com   watch   feature   e   wikipedia   hour   oakland   skyline   earphone   relate   disappear')\n",
      "('topic', 7, ':', u'video   game   reddit   zombie   movie   nap   metal   jerky   seuss   burrito   def   crazy   jungle   pasta   beef')\n",
      "('topic', 8, ':', u'sex   fun   bedroom   pant   step   woman   eye   one   workin   lookin   hard   satisfy   look   take   lol')\n",
      "('topic', 9, ':', u'ashton   perspective   soggy   feed   crafty   camper   emotionally   breakfast   ultra   stalker   dirty   bitch   communication   tuck   teacher')\n"
     ]
    }
   ],
   "source": [
    "drugs_essays = list(corpus.get_docs(\n",
    "            lambda doc: doc.metadata['drugs'] == 'sometimes' or doc.metadata['drugs'] == 'often'))\n",
    "# Build dtm\n",
    "doc_term_matrix, id2term = corpus.as_doc_term_matrix(\n",
    "    (doc.as_terms_list(words=True, ngrams=False, named_entities=True)\n",
    "     for doc in drugs_essays),\n",
    "    weighting='tfidf', normalize=True, smooth_idf=True, min_df=2, max_df=0.95)\n",
    "# Fit model\n",
    "model = textacy.tm.TopicModel('nmf', n_topics=10)\n",
    "model.fit(doc_term_matrix)\n",
    "doc_topic_matrix = model.transform(doc_term_matrix)\n",
    "for topic_idx, top_terms in model.top_topic_terms(id2term, top_n=15):\n",
    "    print('topic', topic_idx, ':', '   '.join(top_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Improve  function to deal with multiple conditions (e.g. \"male\" and \"gay\", drinks \"very often\" or \"desperately\")\n",
    "### Try topic model on shorter essays individually?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
