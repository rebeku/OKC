{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rewrite code from Feature_importance_effficienter.ipynb to run on faves.csv instead of tfidf vectorized essays.\n",
    "\n",
    "# Skip first part of code as no tf-idf vectorization necessary\n",
    "# Save faves as 'tf' so remainder of code will run on it.\n",
    "\n",
    "# adjust indexing\n",
    "# tf.iloc[:,:2000] adjusted to appropriate feature length (currently 1046 but may be adjusted if I drop more titles)\n",
    "# save appropriate length as length\n",
    "# tf.iloc[:,:2000] become tf.iloc[:,:length]\n",
    "\n",
    "# change top_words.csv to top_faves.csv\n",
    "\n",
    "# change 'df' to 'faves' in FILENAMES ONLY to avoid saving over important files\n",
    "# e.g. df_drinks.to_csv('../Assets/Tableau/df_drinks.csv') becomes df_drinks.to_csv('../Assets/Tableau/faves_drinks.csv')\n",
    "\n",
    "# Time permitting, try redoing with cog\n",
    "\n",
    "# remove %matplotlib inline\n",
    "# works on .ipynb only\n",
    "\n",
    "# remove all lines that include a .drop.  Rows being dropped will not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# .py file created from .ipynb by running the following in the terminal:\n",
    "# jupyter nbconvert --to python Feature_importance_efficienter.ipynb\n",
    "# be sure to save a copy of jupyter notebook prior to running the above command!!!\n",
    "# file DOES NOT RUN immediately following conversion due to certain Jupyter notebook specific commands\n",
    "\n",
    "f = open('Feature_importance_efficienter.py', 'r')\n",
    "code = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Beginning of code is significantly different\n",
    "# Rewrite manually\n",
    "\n",
    "beginning = '''\n",
    "\n",
    "# This code is generated with Feature_importance_bbmf.ipynb\n",
    "# based on code from Feature_importance_efficienter.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import re\n",
    "\n",
    "okc = pd.read_csv('../Assets/A/one_long_essay.csv', index_col='Unnamed: 0')\n",
    "tf = pd.read_csv('../Assets/A/faves.csv', index_col='Unnamed: 0')\n",
    "\n",
    "### Drop problematic/questionable values from faves\n",
    "# Return to this section and expand as you identify new \"favorites\" that are most likely regex false positives in most cases.\n",
    "\n",
    "# Most references to \"love\" are not the 2015 3-d erotic film, but more likely to be \"I love Harry Potter!\"\n",
    "# \"Chocolat\" will be selected for those people whose favorite food is chocolate as well as those who enjoy th 2001 French film\n",
    "# Similarly, 'it', '...', 'yes', '2', 'i', 'the', 'currently' 'and', 'oh', 'etc', 'big' and 'eat', 'tron', and 'pi' are most likely not titles or even necessarily whole words.\n",
    "# 'Kurt Vonnegut' will select for a subset of 'Vonnegut' mentions.  Does not contribute new insight.\n",
    "# 'elf' will be picked up by any mention of 'self'\n",
    "# 'fiction' will pick up all mentions of non-fiction\n",
    "# 'up' is most likely not the amazing animated movie :-(\n",
    "# can I improve my regex so it only searches for whole words?\n",
    "# TRY THAT LATER!\n",
    "\n",
    "tf = tf.drop(['love', 'night', 'heat', 'rant', 'saw', 'chocolat', 'it', '...', 'yes', '2', 'i', 'the', 'currently', 'and', 'oh', 'etc', 'big', 'eat', 'tron', 'the hangover', 'pi', 'kurt vonnegut', 'elf', 'fiction', 'up'], axis=1)\n",
    "length = tf.shape[1]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adjust indexing\n",
    "# tf.iloc[:,:2000] adjusted to appropriate feature length (currently 1046 but may be adjusted if I drop more titles)\n",
    "# save appropriate length as length\n",
    "# tf.iloc[:,:2000] become tf.iloc[:,:length]\n",
    "\n",
    "code = code.replace('2000', 'length')\n",
    "\n",
    "# Save lists of top features to be half length (100 instead of 200, 50 instead of 100)\n",
    "# All 2000's have already been replaced, so these will not be mistakenly written over\n",
    "code = code.replace('200', '100')\n",
    "\n",
    "# change top_words.csv to top_faves.csv\n",
    "code = code.replace('top_words.csv', 'top_faves.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# change 'df' to 'faves' in FILENAMES ONLY to avoid saving over important files\n",
    "# e.g. df_drinks.to_csv('../Assets/Tableau/df_drinks.csv') becomes df_drinks.to_csv('../Assets/Tableau/faves_drinks.csv')\n",
    "\n",
    "# Look for any time df appears BETWEEN (Tableau/) and (.csv)\n",
    "code = re.sub('Tableau\\/df', 'Tableau/faves', code)\n",
    "\n",
    "# remove all lines that include a .drop.  Rows being dropped from tf-idf will not exist in faves.\n",
    "\n",
    "code = re.sub('.*drop.*', '', code)\n",
    "\n",
    "# remove line including %matplotlib inline\n",
    "\n",
    "code = re.sub('\\\\n.*\\.?%matplotlib inline.*?\\\\n', '', code)\n",
    "\n",
    "# remove any line containing 'get_ipython'\n",
    "# These are notebook specific and unnecessary for script\n",
    "\n",
    "code = re.sub('\\\\n.*\\.?get_ipython.*?\\\\n', '', code)\n",
    "\n",
    "# replace all instances of number 100 with 50 EXCEPT in income section where 100000 and 100k should remain untouched\n",
    "code = re.sub('100\\]', '50]', code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove beginning of code prior to '# Save any features we might want to filter by to tf dataframe'\n",
    "# replace with beginning\n",
    "\n",
    "code = beginning + code.split('# Save any features we might want to filter by to tf dataframe', 1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Saves script to save faves by subgroup\n",
    "f = open(\"faves.py\",\"w\")\n",
    "\n",
    "f.write(code)\n",
    "\n",
    "f.close()\n",
    "\n",
    "# after running this code run the following in your terminal to save top faves for each group:\n",
    "\n",
    "# python faves.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# This code is generated with Feature_importance_bbmf.ipynb\n",
      "# based on code from Feature_importance_efficienter.ipynb\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from time import time\n",
      "import re\n",
      "\n",
      "okc = pd.read_csv('../Assets/A/one_long_essay.csv', index_col='Unnamed: 0')\n",
      "tf = pd.read_csv('../Assets/A/faves.csv', index_col='Unnamed: 0')\n",
      "\n",
      "### Drop problematic/questionable values from faves\n",
      "# Return to this section and expand as you identify new \"favorites\" that are most likely regex false positives in most cases.\n",
      "\n",
      "# Most references to \"love\" are not the 2015 3-d erotic film, but more likely to be \"I love Harry Potter!\"\n",
      "# \"Chocolat\" will be selected for those people whose favorite food is chocolate as well as those who enjoy th 2001 French film\n",
      "# Similarly, 'it', '...', 'yes', '2', 'i', 'the', 'currently' 'and', 'oh', 'etc', 'big' and 'eat', 'tron', and 'pi' are most likely not titles or even necessarily whole words.\n",
      "# 'Kurt Vonnegut' will select for a subset of 'Vonnegut' mentions.  Does not contribute new insight.\n",
      "# 'elf' will be picked up by any mention of 'self'\n",
      "# 'fiction' will pick up all mentions of non-fiction\n",
      "# 'up' is most likely not the amazing animated movie :-(\n",
      "# can I improve my regex so it only searches for whole words?\n",
      "# TRY THAT LATER!\n",
      "\n",
      "tf = tf.drop(['love', 'night', 'heat', 'rant', 'saw', 'chocolat', 'it', '...', 'yes', '2', 'i', 'the', 'currently', 'and', 'oh', 'etc', 'big', 'eat', 'tron', 'the hangover', 'pi', 'kurt vonnegut', 'elf', 'fiction', 'up'], axis=1)\n",
      "length = tf.shape[1]\n",
      "\n",
      "\n",
      "features = ['age', 'body_type', 'diet', 'drinks', 'drugs', 'education', 'ethnicity', \n",
      "           'height', 'income', 'job', 'offspring', 'orientation', 'pets', 'religion', \n",
      "            'sex', 'sign', 'smokes', 'speaks']\n",
      "\n",
      "\n",
      "# In[8]:\n",
      "\n",
      "for feature in features:\n",
      "    tf['X%s' %feature] = okc[feature]\n",
      "\n",
      "\n",
      "# In[9]:\n",
      "\n",
      "# Handle some common conjunctions which get separated from words\n",
      "# leading to features like 'don' and 'll\n",
      "\n",
      "tf = tf.rename(columns = {'don':\"don't\", 'll':\"i'll\", 've':\"i've\"})\n",
      "\n",
      "\n",
      "# ### Find top words by tf-idf score\n",
      "\n",
      "# In[10]:\n",
      "\n",
      "mean_words = tf.iloc[:,:length].mean(axis=0)\n",
      "mean_words.sort_values(inplace=True, ascending=False)\n",
      "\n",
      "\n",
      "# In[11]:\n",
      "\n",
      "# add something to this for hue?\n",
      "mean_words[:60].to_csv('../Assets/Tableau/top_faves.csv')\n",
      "\n",
      "\n",
      "# In[12]:\n",
      "\n",
      "# Save a single string with top words for each category.  This list will be exported to a .txt file at end of script\n",
      "all_lists = ''\n",
      "\n",
      "\n",
      "# ### Compare word frequency for men vs. women\n",
      "\n",
      "# In[13]:\n",
      "\n",
      "# Compute mean value of each of first length columns for men\n",
      "t0 = time()\n",
      "mdf = tf[tf.Xsex=='m']\n",
      "df = pd.DataFrame(mdf.iloc[:,:length].mean(axis=0), columns = ['m'])\n",
      "print time()-t0\n",
      "\n",
      "\n",
      "# In[14]:\n",
      "\n",
      "# Compute mean value of each of first length columns for women\n",
      "t0 = time()\n",
      "fdf = tf[tf.Xsex == 'f']\n",
      "df['f'] = fdf.iloc[:,:length].mean(axis=0)\n",
      "print time()-t0\n",
      "\n",
      "\n",
      "# In[15]:\n",
      "\n",
      "df['diff'] = df['m']-df['f']\n",
      "\n",
      "\n",
      "# In[16]:\n",
      "\n",
      "df.sort_values('diff', inplace=True)\n",
      "\n",
      "\n",
      "# In[17]:\n",
      "\n",
      "# Save top 50]words for women and men for report\n",
      "women_list = ''\n",
      "for word in df.index[:50]:\n",
      "    women_list = women_list + word + ', '\n",
      "    \n",
      "men_list = ''\n",
      "# Write men_list in reverse order so most popular words are on top\n",
      "for i in range(-1, -50] -1):\n",
      "    men_list = men_list + df.index[i] + ', '\n",
      "    \n",
      "all_lists = 'Women \\n \\n' + women_list + '\\n\\n Men \\n\\n' + men_list\n",
      "\n",
      "\n",
      "# In[18]:\n",
      "\n",
      "# Save top 30 from each cat\n",
      "# women\n",
      "df.sort_values('diff', inplace=True)\n",
      "f = pd.DataFrame(df.head(30)['f'])\n",
      "f.columns = ['tfidf']\n",
      "f['label'] = 'female'\n",
      "\n",
      "# men\n",
      "df.sort_values('diff', inplace=True, ascending=False)\n",
      "m = pd.DataFrame(df.head(30)['m'])\n",
      "m.columns = ['tfidf']\n",
      "m['label'] = 'male'\n",
      "\n",
      "\n",
      "df_sex = pd.concat([m, f], axis=0)\n",
      "\n",
      "df_sex.to_csv('../Assets/Tableau/faves_sex.csv')\n",
      "\n",
      "\n",
      "# ### Compare word frequency for social drinkers vs. heavy drinkers vs. non drinkers\n",
      "\n",
      "# In[19]:\n",
      "\n",
      "# Compare word frequency for social drinkers vs. heavy drinkers vs. non drinkers\n",
      "\n",
      "# Compute mean value of each of first length columns for social drinks\n",
      "t0 = time()\n",
      "ddf = tf[tf.Xdrinks=='socially']\n",
      "df = pd.DataFrame(ddf.iloc[:,:length].mean(axis=0), columns = ['social'])\n",
      "print time()-t0\n",
      "\n",
      "\n",
      "# In[20]:\n",
      "\n",
      "# Compute mean value of each of first length columns for non-drinkers\n",
      "t0 = time()\n",
      "ddf = tf.query(\"Xdrinks == 'rarely'|Xdrinks == 'not at all'\")\n",
      "df['non-drinker'] = ddf.iloc[:,:length].mean(axis=0)\n",
      "print time()-t0\n",
      "\n",
      "\n",
      "# In[21]:\n",
      "\n",
      "# Compute mean value of each of first length columns for heavy drinkers\n",
      "t0 = time()\n",
      "ddf = tf.query(\"Xdrinks == 'often'|Xdrinks == 'very often'|Xdrinks == 'desperately'\")\n",
      "df['heavy'] = ddf.iloc[:,:length].mean(axis=0)\n",
      "print time()-t0\n",
      "\n",
      "\n",
      "# In[22]:\n",
      "\n",
      "df['avg'] = df.mean(axis=1)\n",
      "# Compute differences between social drinkers' values and other categories\n",
      "df['nd_diff'] = df['non-drinker'] - df['avg']\n",
      "df['h_diff'] = df['heavy'] - df['avg']\n",
      "df['s_diff'] = df['social'] - df['avg']\n",
      "\n",
      "\n",
      "# In[23]:\n",
      "\n",
      "# Save top 50]words for heavy, social, and non-drinkers for report\n",
      "# heavy drinkers:\n",
      "df.sort_values('h_diff', ascending=False, inplace=True)\n",
      "\n",
      "heavy_list = ''\n",
      "for word in df.index[:50]:\n",
      "    heavy_list = heavy_list + word + ', '\n",
      "\n",
      "# social drinkers:\n",
      "df.sort_values('s_diff', ascending=False, inplace=True)\n",
      "\n",
      "social_list = ''\n",
      "for word in df.index[:50]:\n",
      "    social_list = social_list + word + ', '\n",
      "    \n",
      "# non-drinkers:\n",
      "df.sort_values('nd_diff', ascending=False, inplace=True)\n",
      "\n",
      "non_list = ''\n",
      "for word in df.index[:50]:\n",
      "    non_list = non_list + word + ', '\n",
      "    \n",
      "all_lists = all_lists +  '\\n\\nDrink heavily \\n \\n' +  heavy_list + '\\n\\nDrink socially \\n\\n' + social_list + '\\n\\nDo not drink regularly \\n\\n'+ non_list\n",
      "\n",
      "\n",
      "# In[24]:\n",
      "\n",
      "# Save top 18 from each cat\n",
      "# non-drinkers first\n",
      "df.sort_values('nd_diff', inplace=True, ascending=False)\n",
      "nd = pd.DataFrame(df.head(18)['non-drinker'])\n",
      "nd.columns = ['tfidf']\n",
      "nd['label'] = 'non-drinker'\n",
      "\n",
      "# social drinkers\n",
      "df.sort_values('s_diff', inplace=True, ascending=False)\n",
      "sd = pd.DataFrame(df.head(18)['social'])\n",
      "sd.columns = ['tfidf']\n",
      "sd['label'] = 'social'\n",
      "\n",
      "# heavy drinkers\n",
      "df.sort_values('h_diff', inplace=True, ascending=False)\n",
      "hd = pd.DataFrame(df.head(18)['heavy'])\n",
      "hd.columns = ['tfidf']\n",
      "hd['label'] = 'heavy'\n",
      "\n",
      "df_drinks = pd.concat([nd, sd, hd], axis=0)\n",
      "\n",
      "df_drinks.to_csv('../Assets/Tableau/faves_drinks.csv')\n",
      "\n",
      "\n",
      "# ### Explore word choice by age\n",
      "\n",
      "# In[25]:\n",
      "\n",
      "from matplotlib import pyplot as plt\n",
      "\n",
      "# In[26]:\n",
      "\n",
      "plt.hist(okc.age, 50, normed=1, facecolor='green', alpha=0.75)\n",
      "plt.axis([15, 80, 0, .1])\n",
      "plt.show\n",
      "\n",
      "\n",
      "# In[27]:\n",
      "\n",
      "# Compare under 30 to over 30\n",
      "\n",
      "def age_encoder(age):\n",
      "    if age ==0:\n",
      "        return np.nan\n",
      "    elif age < 30:\n",
      "        return 0\n",
      "    else:\n",
      "        return 1\n",
      "    \n",
      "tf.Xage = tf.Xage.apply(age_encoder)\n",
      "\n",
      "\n",
      "# In[28]:\n",
      "\n",
      "# Compare word frequency for under 30 vs. over 30\n",
      "\n",
      "# Compute mean value of each of first length columns for over 30\n",
      "t0 = time()\n",
      "odf = tf[tf.Xage==1]\n",
      "df = pd.DataFrame(odf.iloc[:,:length].mean(axis=0), columns = ['>30'])\n",
      "print time()-t0\n",
      "\n",
      "# Compute mean value of each of first length columns for under 30\n",
      "ydf = tf[tf.Xage == 0]\n",
      "df['<30'] = ydf.iloc[:,:length].mean(axis=0)\n",
      "print time()-t0\n",
      "\n",
      "\n",
      "# In[29]:\n",
      "\n",
      "df['diff'] = df['>30']-df['<30']\n",
      "df.sort_values('diff', inplace=True)\n",
      "\n",
      "\n",
      "# In[30]:\n",
      "\n",
      "# Save top 50]words for people under and over 30\n",
      "# older people:\n",
      "df.sort_values('diff', ascending=False, inplace=True)\n",
      "\n",
      "older_list = ''\n",
      "for word in df.index[:50]:\n",
      "    older_list = older_list + word + ', '\n",
      "\n",
      "# younger people\n",
      "younger_list = ''\n",
      "# Write older_list in reverse order so most popular words are on top\n",
      "for i in range(-1, -50] -1):\n",
      "    younger_list = younger_list + df.index[i] + ', '\n",
      "    \n",
      "all_lists = all_lists + '\\n\\nOver 30 \\n \\n' + older_list + '\\n\\nUnder 30 \\n\\n' + younger_list\n",
      "\n",
      "\n",
      "# In[31]:\n",
      "\n",
      "# Save top 30 from each cat\n",
      "# n.b terms younger and older are strictly relative\n",
      "\n",
      "# younger\n",
      "df.sort_values('diff', inplace=True)\n",
      "y = pd.DataFrame(df.head(30)['<30'])\n",
      "y.columns = ['tfidf']\n",
      "y['label'] = '<30'\n",
      "\n",
      "# older\n",
      "df.sort_values('diff', inplace=True, ascending=False)\n",
      "o = pd.DataFrame(df.head(30)['>30'])\n",
      "o.columns = ['tfidf']\n",
      "o['label'] = '>30'\n",
      "\n",
      "\n",
      "df_age = pd.concat([y, o], axis=0)\n",
      "\n",
      "df_age.to_csv('../Assets/Tableau/faves_age.csv')\n",
      "\n",
      "\n",
      "# ### Compare drug users and non-users\n",
      "# exclude those who don't report\n",
      "\n",
      "# In[32]:\n",
      "\n",
      "def drug_encoder(drugs):\n",
      "    if drugs == 'never':\n",
      "        return 0\n",
      "    elif drugs == 'sometimes' or drugs == 'often':\n",
      "        return 1\n",
      "    else:\n",
      "        return np.nan\n",
      "    \n",
      "tf.Xdrugs = tf.Xdrugs.apply(drug_encoder)\n",
      "\n",
      "\n",
      "# In[33]:\n",
      "\n",
      "# Compute mean value of each of first length columns for drug users\n",
      "t0 = time()\n",
      "udf = tf[tf.Xdrugs==1]\n",
      "df = pd.DataFrame(odf.iloc[:,:length].mean(axis=0), columns = ['users'])\n",
      "print time()-t0\n",
      "\n",
      "# Compute mean value of each of first length columns for non-users\n",
      "ydf = tf[tf.Xdrugs == 0]\n",
      "df['non-users'] = ydf.iloc[:,:length].mean(axis=0)\n",
      "print time()-t0\n",
      "\n",
      "\n",
      "# In[34]:\n",
      "\n",
      "df['diff'] = df['users']-df['non-users']\n",
      "df.sort_values('diff', inplace=True)\n",
      "\n",
      "\n",
      "# In[35]:\n",
      "\n",
      "# Save top 50]words for users and non-users\n",
      "# users:\n",
      "df.sort_values('diff', ascending=False, inplace=True)\n",
      "\n",
      "non_user_list = ''\n",
      "for word in df.index[:50]:\n",
      "    non_user_list = non_user_list + word + ', '\n",
      "\n",
      "# non-users\n",
      "user_list = ''\n",
      "# Write older_list in reverse order so most popular words are on top\n",
      "for i in range(-1, -50] -1):\n",
      "    user_list = user_list + df.index[i] + ', '\n",
      "    \n",
      "all_lists = all_lists + '\\n\\nUse drugs \\n \\n' + user_list + '\\n\\nDo not use drugs \\n\\n' + non_user_list\n",
      "\n",
      "\n",
      "# In[36]:\n",
      "\n",
      "# Save top 30 from each cat\n",
      "# non-users\n",
      "\n",
      "n = pd.DataFrame(df.head(30)['non-users'])\n",
      "n.columns = ['tfidf']\n",
      "n['label'] = 'non-users'\n",
      "\n",
      "# users\n",
      "\n",
      "m = pd.DataFrame(df.tail(30)['users'])\n",
      "m.columns = ['tfidf']\n",
      "m['label'] = 'users'\n",
      "\n",
      "\n",
      "df_drugs = pd.concat([m, n], axis=0)\n",
      "\n",
      "df_drugs.to_csv('../Assets/Tableau/faves_drugs.csv')\n",
      "\n",
      "\n",
      "# ### Explore Income\n",
      "\n",
      "# In[37]:\n",
      "\n",
      "plt.hist(tf.Xincome[tf.Xincome != -1], 50, normed=1, facecolor='green', alpha=0.75)\n",
      "plt.show\n",
      "\n",
      "\n",
      "# In[38]:\n",
      "\n",
      "# Divide income income into <50k, 50-100k, >100k\n",
      "\n",
      "def income_encoder(income):\n",
      "    if income == -1:\n",
      "        return -1\n",
      "    elif income <= 50000:\n",
      "        return 0\n",
      "    elif income <= 100000:\n",
      "        return 1\n",
      "    else:\n",
      "        return 2\n",
      "    \n",
      "tf.Xincome = tf.Xincome.apply(income_encoder)\n",
      "\n",
      "\n",
      "# In[39]:\n",
      "\n",
      "# Compare word frequency for different income levels\n",
      "\n",
      "# Compute mean value of each of first length columns for lower income\n",
      "t0 = time()\n",
      "pdf = tf[tf.Xincome==0]\n",
      "df = pd.DataFrame(pdf.iloc[:,:length].mean(axis=0), columns = ['<50k'])\n",
      "print time()-t0\n",
      "\n",
      "# Compute mean value of each of first length columns for middle income\n",
      "t0 = time()\n",
      "mdf = tf[tf.Xincome==1]\n",
      "df['50-100k'] = mdf.iloc[:,:length].mean(axis=0)\n",
      "print time()-t0\n",
      "\n",
      "# Compute mean value of each of first length columns for highest income\n",
      "t0 = time()\n",
      "rdf = tf[tf.Xincome==2]\n",
      "df['>100k'] = rdf.iloc[:,:length].mean(axis=0)\n",
      "print time()-t0\n",
      "\n",
      "\n",
      "# Compute differences between each income category and overall average\n",
      "df['avg'] = df.mean(axis=1)\n",
      "df['r_diff'] = df['>100k'] - df['avg']\n",
      "df['p_diff'] = df['<50k'] - df['avg']\n",
      "df['m_diff'] = df['50-100k'] - df['avg']\n",
      "\n",
      "\n",
      "# In[40]:\n",
      "\n",
      "# Save lists for each income bracket\n",
      "\n",
      "df.sort_values('r_diff', ascending=False, inplace=True)\n",
      "\n",
      "upper_list = ''\n",
      "for word in df.index[:50]:\n",
      "    upper_list = upper_list + word + ', '\n",
      "    \n",
      "df.sort_values('m_diff', ascending=False, inplace=True)\n",
      "\n",
      "mid_list = ''\n",
      "for word in df.index[:50]:\n",
      "    mid_list = mid_list + word + ', '\n",
      "    \n",
      "\n",
      "df.sort_values('p_diff', ascending=False, inplace=True)    \n",
      "lower_list = ''\n",
      "for word in df.index[:50]:\n",
      "    lower_list = lower_list + word + ', '\n",
      "\n",
      "all_lists = all_lists + '\\n\\nMake over 100k annually \\n \\n' + upper_list + '\\n\\nMake 50-100k annually\\n\\n' + mid_list+ '\\n\\nMake less than 50k annually\\n\\n'+lower_list\n",
      "\n",
      "\n",
      "# In[41]:\n",
      "\n",
      "print all_lists\n",
      "\n",
      "\n",
      "# In[42]:\n",
      "\n",
      "# Save top 18 from each cat\n",
      "# richest first\n",
      "df.sort_values('r_diff', inplace=True, ascending=False)\n",
      "df2 = pd.DataFrame(df.head(18)['>100k'])\n",
      "df2.columns = ['tfidf']\n",
      "df2['label'] = '> 100k'\n",
      "\n",
      "# middle income\n",
      "df.sort_values('m_diff', inplace=True, ascending=False)\n",
      "df3 = pd.DataFrame(df.head(18)['50-100k'])\n",
      "df3.columns = ['tfidf']\n",
      "df3['label'] = '50 - 100k'\n",
      "\n",
      "# lower income\n",
      "df.sort_values('p_diff', inplace=True, ascending=False)\n",
      "df4 = pd.DataFrame(df.head(18)['<50k'])\n",
      "df4.columns = ['tfidf']\n",
      "df4['label'] = '< 50k'\n",
      "\n",
      "df_income = pd.concat([df2, df3, df4], axis=0)\n",
      "df_income.to_csv('../Assets/Tableau/faves_income.csv')\n",
      "\n",
      "\n",
      "# ### Compare dog and cat people\n",
      "\n",
      "# In[43]:\n",
      "\n",
      "# calculate dummy columns for likes dogs and likes cats\n",
      "# will be some overlap since not mutually exclusive\n",
      "\n",
      "def mask_dogs(pets):\n",
      "    # catches 'has dogs' or 'likes dogs'\n",
      "    try:\n",
      "        if pets.find('dogs') > -1:\n",
      "            if pets.find('dislikes dogs') == -1:\n",
      "                return 1\n",
      "        else:\n",
      "            return 0\n",
      "    except:\n",
      "        return 0\n",
      "    \n",
      "def mask_cats(pets):\n",
      "    try:\n",
      "        if pets.find('cats') > -1:\n",
      "            if pets.find('dislikes cats') == -1:\n",
      "                return 1\n",
      "        else:\n",
      "            return 0\n",
      "    except:\n",
      "        return 0\n",
      "\n",
      "tf['Xdogs'] = tf.Xpets.apply(mask_dogs)\n",
      "tf['Xcats'] = tf.Xpets.apply(mask_cats)\n",
      "\n",
      "\n",
      "# In[44]:\n",
      "\n",
      "# find mean scores for dog people\n",
      "\n",
      "t0 = time()\n",
      "ddf = tf[tf.Xdogs==1]\n",
      "df = pd.DataFrame(ddf.iloc[:,:length].mean(axis=0), columns = ['dogs'])\n",
      "print time()-t0\n",
      "\n",
      "# find mean scores for cat people\n",
      "cdf = tf[tf.Xcats == 1]\n",
      "df['cats'] = cdf.iloc[:,:length].mean(axis=0)\n",
      "print time()-t0\n",
      "\n",
      "\n",
      "# In[45]:\n",
      "\n",
      "df['diff'] = df['dogs'] - df['cats']\n",
      "df.sort_values('diff', inplace=True)\n",
      "\n",
      "\n",
      "# In[46]:\n",
      "\n",
      "# remove cat, cats, dog and dogs from this list since they don't contribute insight\n",
      "\n",
      "\n",
      "\n",
      "# In[47]:\n",
      "\n",
      "# Save top 50]words for cats and dogs for report\n",
      "cat_list = ''\n",
      "for word in df.index[:50]:\n",
      "    cat_list = cat_list + word + ', '\n",
      "    \n",
      "dog_list = ''\n",
      "# Write dog_list in reverse order so most popular words are on top\n",
      "for i in range(-1, -50] -1):\n",
      "    dog_list = dog_list + df.index[i] + ', '\n",
      "    \n",
      "all_lists = all_lists + '\\n\\nLike cats\\n \\n' + cat_list + '\\n\\nLike dogs \\n\\n' + dog_list\n",
      "\n",
      "\n",
      "# In[48]:\n",
      "\n",
      "# Save top 30 from each cat\n",
      "# cats\n",
      "\n",
      "n = pd.DataFrame(df.head(30)['cats'])\n",
      "n.columns = ['tfidf']\n",
      "n['label'] = 'cats'\n",
      "\n",
      "# men\n",
      "\n",
      "m = pd.DataFrame(df.tail(30)['dogs'])\n",
      "m.columns = ['tfidf']\n",
      "m['label'] = 'dogs'\n",
      "\n",
      "\n",
      "df_drugs = pd.concat([m, n], axis=0)\n",
      "\n",
      "df_drugs.to_csv('../Assets/Tableau/faves_pets.csv')\n",
      "\n",
      "\n",
      "# ### Explore word choice by education\n",
      "# \n",
      "# college grad? 1 or 0.\n",
      "\n",
      "# In[49]:\n",
      "\n",
      "def ed_encoder(ed):\n",
      "    # a person is a college grad if they either \"graduated from college/university\"\n",
      "    # or mention law school, med, school, masters program or ph. d program (all instances of the word program are graduate )\n",
      "    try:\n",
      "        if ed == 'graduated from college/university' or ed.find('law') >= 0 or ed.find('med') >= 0 or ed.find('program') >= 0:\n",
      "            return 1\n",
      "        # space camp answers are facetious and must be excluded\n",
      "        # BTW I am in space camp right now\n",
      "        elif ed.find('space camp') >= 0:\n",
      "            return np.nan\n",
      "        else: return 0\n",
      "    except:\n",
      "        return np.nan\n",
      "\n",
      "tf.Xeducation = tf.Xeducation.apply(ed_encoder)\n",
      "\n",
      "\n",
      "# In[50]:\n",
      "\n",
      "# Compare word frequency for college educated vs. not college\n",
      "\n",
      "# Compute mean value of each of first length columns for college\n",
      "t0 = time()\n",
      "df2 = tf[tf.Xage==1]\n",
      "df = pd.DataFrame(df2.iloc[:,:length].mean(axis=0), columns = ['grad'])\n",
      "print time()-t0\n",
      "\n",
      "# Compute mean value of each of first length columns for under 30\n",
      "df2 = tf[tf.Xage == 0]\n",
      "df['non-grad'] = df2.iloc[:,:length].mean(axis=0)\n",
      "print time()-t0\n",
      "\n",
      "df['diff'] = df['grad'] - df['non-grad']\n",
      "df.sort_values('diff', inplace=True)\n",
      "\n",
      "# Save top 50]words for grads and non-grads for report\n",
      "non_grad_list = ''\n",
      "for word in df.index[:50]:\n",
      "    non_grad_list = non_grad_list + word + ', '\n",
      "    \n",
      "grad_list = ''\n",
      "# Write grad_list in reverse order so most popular words are on top\n",
      "for i in range(-1, -50] -1):\n",
      "    grad_list = grad_list + df.index[i] + ', '\n",
      "\n",
      "# Save top 50]s lists to all_lists\n",
      "all_lists =  all_lists + '\\n\\nGraduated College\\n \\n' + grad_list + '\\n\\nDid Not Graduate College\\n\\n' + non_grad_list\n",
      "\n",
      "# Save top 30 from each cat\n",
      "# non-grads\n",
      "\n",
      "n = pd.DataFrame(df.head(30)['non-grad'])\n",
      "n.columns = ['tfidf']\n",
      "n['label'] = 'non-grads'\n",
      "\n",
      "# grads\n",
      "df.sort_values('diff', inplace=True, ascending=False)\n",
      "g = pd.DataFrame(df.head(30)['grad'])\n",
      "g.columns = ['tfidf']\n",
      "g['label'] = 'grads'\n",
      "\n",
      "\n",
      "df_ed = pd.concat([n, g], axis=0)\n",
      "\n",
      "df_ed.to_csv('../Assets/Tableau/faves_ed.csv')\n",
      "\n",
      "\n",
      "\n",
      "# ### Explore word choice by ethnicity\n",
      "# \n",
      "# options are: asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin, white\n",
      "\n",
      "# In[51]:\n",
      "\n",
      "# It will be more efficient to encode dummies for each ethnic group than to search each entry\n",
      "# People who list multiple ethnicities will count for all ethnicities listed\n",
      "\n",
      "# write encoder for each ethnicity\n",
      "\n",
      "groups = ['asian', 'middle eastern', 'black', 'native american', 'indian', 'pacific islander', 'hispanic / latin', 'white']\n",
      "\n",
      "for ethnicity in groups:\n",
      "    def ethnicity_encoder(eth):\n",
      "        global ethnicity\n",
      "        try:\n",
      "            if eth.find(ethnicity) >= 0:\n",
      "                return 1\n",
      "            else: return 0\n",
      "        except:\n",
      "            return 0\n",
      "        \n",
      "    tf['X%s' %ethnicity] = tf.Xethnicity.apply(ethnicity_encoder)\n",
      "\n",
      "\n",
      "# In[52]:\n",
      "\n",
      "df=pd.DataFrame(index=tf.columns[:length])\n",
      "# Compute mean value of each of first length columns for each ethnic group\n",
      "for ethnicity in groups:\n",
      "    t0 = time()\n",
      "    df2 = tf[tf['X%s' %ethnicity] == 1]\n",
      "    df[ethnicity] = pd.DataFrame(df2.iloc[:,:length].mean(axis=0))\n",
      "    print time()-t0\n",
      "    \n",
      "df['avg'] = df.mean(axis=1)\n",
      "\n",
      "for ethnicity in groups:\n",
      "    df['%s_diff' %ethnicity] = df[ethnicity] - df['avg']\n",
      "\n",
      "\n",
      "# In[53]:\n",
      "\n",
      "# List top 50]words for each ethnicity\n",
      "\n",
      "\n",
      "# Fill string for each ethnicity with top words\n",
      "for ethnicity in groups:\n",
      "    df.sort_values('%s_diff' %ethnicity, ascending=False, inplace=True)\n",
      "    \n",
      "    eth_list = ''\n",
      "    for word in df.index[:50]:\n",
      "        eth_list = eth_list + word + ', '\n",
      "    all_lists = all_lists + '\\n\\n%s\\n\\n' %ethnicity + eth_list\n",
      "    \n",
      "\n",
      "\n",
      "# In[54]:\n",
      "\n",
      "# There are 8 different ethnic groups available\n",
      "# Tableau does well with about 50 to 60 words for packed bubbles\n",
      "# Take top 7 words for each ethnicity\n",
      "\n",
      "# Drop words asian, middle, eastern, indian, and india as they are top ranking words but redundant with categories\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# In[55]:\n",
      "\n",
      "# must have at least one row in dataframe in order to use pd.concat\n",
      "df_ethnicity = pd.DataFrame(index=[0], columns=['tfidf', 'label'])\n",
      "\n",
      "for ethnicity in groups:\n",
      "    # Save top 7 words for each ethnicity\n",
      "    df.sort_values('%s_diff' %ethnicity, ascending=False, inplace=True)\n",
      "    df3 = pd.DataFrame(df.head(7)[ethnicity])\n",
      "    df3.columns=['tfidf']\n",
      "    df3['label'] = ethnicity\n",
      "    \n",
      "    df_ethnicity = pd.concat([df_ethnicity, df3], axis=0)\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "df_ethnicity.to_csv('../Assets/Tableau/faves_ethnicity.csv')\n",
      "    \n",
      "\n",
      "\n",
      "# ### Explore jobs\n",
      "\n",
      "# In[56]:\n",
      "\n",
      "\n",
      "df = pd.DataFrame(index=tf.columns[:length])\n",
      "df_jobs = pd.DataFrame(index=[0], columns=['tfidf', 'label'])\n",
      "job_dic = {}\n",
      "# Most popular job category is \"other\"  Exclude that\n",
      "for job in tf.Xjob.value_counts()[1:11].index:\n",
      "    # Save a column of dummies for each job category\n",
      "    def job_encoder(career):\n",
      "        global job\n",
      "        try:\n",
      "            if career.find(job) >= 0:\n",
      "                return 1\n",
      "            else: return 0\n",
      "        except:\n",
      "            return 0\n",
      "    \n",
      "    tf['X%s' %job] = tf.Xjob.apply(job_encoder)\n",
      "\n",
      "    # Compute mean tfidf scores for job type\n",
      "    t0 = time()\n",
      "    df2 = tf[tf['X%s' %job] == 1]\n",
      "    df[job] = pd.DataFrame(df2.iloc[:,:length].mean(axis=0))\n",
      "    print time()-t0\n",
      "    \n",
      "# Compute overall mean tfidf scores\n",
      "df['avg'] = df.mean(axis=1)\n",
      "\n",
      "    \n",
      "for job in tf.Xjob.value_counts()[1:11].index: \n",
      "    # compute diff between scores for each job and overall mean\n",
      "    df['%s_diff' %job] = df[job] - df['avg']    \n",
      "    \n",
      "\n",
      "    # sort by job\n",
      "    # save top 50]words asfor each job\n",
      "    # save top 6 words with tfidf scores and labels to df_jobs\n",
      "    job_list = ''\n",
      "    df.sort_values('%s_diff' %job, ascending=False, inplace=True)\n",
      "    # save top 50]words to reserved string in job_dic\n",
      "    for word in df.index[:50]:\n",
      "        job_list = job_list + word + ', '\n",
      "    \n",
      "    all_lists = all_lists + '\\n\\n%s\\n\\n' %job + job_list\n",
      "        \n",
      "    # Save top 6 words to df_jobs\n",
      "    df.sort_values('%s_diff' %job, ascending=False, inplace=True)\n",
      "    \n",
      "    df3 = pd.DataFrame(df.head(6)[job])\n",
      "    df3.columns=['tfidf']\n",
      "    df3['label'] = job\n",
      "    \n",
      "    df_jobs = pd.concat([df_jobs, df3], axis=0)\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "df_jobs.to_csv('../Assets/Tableau/faves_jobs.csv')\n",
      "\n",
      "\n",
      "# ### Look at sexual orientation\n",
      "# Break down by gender as well to account for different cultures in queer community\n",
      "# \n",
      "\n",
      "# In[57]:\n",
      "\n",
      "# Compute mean value of each of first length columns for gay men\n",
      "\n",
      "df2 = tf[tf.Xsex=='m'][tf.Xorientation=='gay']\n",
      "df = pd.DataFrame(df2.iloc[:,:length].mean(axis=0), columns = ['gay men'])\n",
      "\n",
      "\n",
      "# Compute mean value of each of first length columns for bi men\n",
      "df2 = tf[tf.Xsex=='m'][tf.Xorientation=='bisexual']\n",
      "df['bi men'] = df2.iloc[:,:length].mean(axis=0)\n",
      "\n",
      "\n",
      "# Compute mean values for straight men\n",
      "df2 = tf[tf.Xsex=='m'][tf.Xorientation=='straight']\n",
      "df['straight men'] = df2.iloc[:,:length].mean(axis=0)\n",
      "\n",
      "\n",
      "# Compute mean values for gay women\n",
      "df2 = tf[tf.Xsex=='f'][tf.Xorientation=='gay']\n",
      "df['gay women'] = df2.iloc[:,:length].mean(axis=0)\n",
      "\n",
      "# Compute mean values for bi women\n",
      "df2 = tf[tf.Xsex=='f'][tf.Xorientation=='bisexual']\n",
      "df['bi women'] = df2.iloc[:,:length].mean(axis=0)\n",
      "\n",
      "# Compute mean values for straight women\n",
      "df2 = tf[tf.Xsex=='f'][tf.Xorientation=='straight']\n",
      "df['straight women'] = df2.iloc[:,:length].mean(axis=0)\n",
      "\n",
      "\n",
      "df['avg'] = df.mean(axis=1)\n",
      "df['gay men diff'] = df['gay men'] - df.avg\n",
      "df['bi men diff'] = df['bi men'] - df.avg\n",
      "df['straight men diff'] = df['straight men'] - df.avg\n",
      "df['gay women diff'] = df['gay women'] - df.avg\n",
      "df['bi women diff'] = df['bi women'] - df.avg\n",
      "df['straight women diff'] = df['straight women'] - df.avg\n",
      "\n",
      "\n",
      "# In[58]:\n",
      "\n",
      "# Save word lists\n",
      "df_orientation = pd.DataFrame(index=[0], columns=['tfidf', 'label'])\n",
      "\n",
      "for group in df.columns[:6]:\n",
      "    df.sort_values('%s diff' %group, ascending=False, inplace=True)\n",
      "    group_list = ''\n",
      "    for word in df.index[:50]:\n",
      "        group_list = group_list + word + ', '\n",
      "    all_lists = all_lists + '\\n\\n%s\\n\\n' %group + group_list\n",
      "# Save df for Tableau with top 10 for each category\n",
      "    df2 = pd.DataFrame(df[group].head(10))\n",
      "    df2.columns = ['tfidf']\n",
      "    df2['label'] = group\n",
      "\n",
      "    \n",
      "    df_orientation = pd.concat([df_orientation, df2], axis=0)\n",
      "    \n",
      "\n",
      "\n",
      "df_orientation.to_csv('../Assets/Tableau/faves_orientation.csv')\n",
      "\n",
      "\n",
      "# ### Explore Religion\n",
      "\n",
      "# In[59]:\n",
      "\n",
      "# list religions \n",
      "religions = []\n",
      "for religion in tf.Xreligion.value_counts().index:\n",
      "    rel = religion.split(' ', 1)[0]\n",
      "    if rel not in religions:\n",
      "        religions.append(rel)\n",
      "religions = filter(lambda x: x != 'other', religions)\n",
      "\n",
      "\n",
      "# In[60]:\n",
      "\n",
      "# Encode dummies for each religion\n",
      "# rel is individual person's religion string \"Christianity and very serious about it\"\n",
      "# religion is each group \"Christianity\"\n",
      "\n",
      "tf.Xreligion.replace(np.nan, '', inplace=True)\n",
      "\n",
      "df = pd.DataFrame()\n",
      "df_religion = pd.DataFrame(index=[0], columns=['tfidf', 'label'])\n",
      "\n",
      "for religion in religions:\n",
      "    tf['X%s' %religion] = tf.Xreligion.apply(lambda rel: 1 if rel.split(' ', 1)[0] == religion else 0)\n",
      "\n",
      "    # Compute mean values for each religion\n",
      "    df2 = tf[tf['X%s' %religion]==1]\n",
      "    df[religion] = df2.iloc[:,:length].mean(axis=0)\n",
      "    \n",
      "# Compute mean for each word across religons\n",
      "df['avg'] = df.mean(axis=1)\n",
      "\n",
      "for religion in religions:\n",
      "    df['%s_diff' %religion] = df[religion] -df['avg']\n",
      "\n",
      "    # Save top 50]words for each religion as string\n",
      "    df.sort_values('%s_diff' % religion, inplace=True, ascending=False)\n",
      "    \n",
      "    rel_list = ''\n",
      "    for word in df.index[:50]:\n",
      "        rel_list = rel_list + word + ', '\n",
      "        \n",
      "    all_lists = all_lists + '\\n\\n%s\\n\\n' %religion + rel_list\n",
      "    \n",
      "    # Save top 7 words for each religon as df for Tableau\n",
      "    df2 = pd.DataFrame(df[religion].head(7))\n",
      "    df2.columns = ['tfidf']\n",
      "    df2['label'] = religion\n",
      "    \n",
      "    df_religion = pd.concat([df_religion, df2], axis=0)\n",
      "    \n",
      "\n",
      "df_religion.to_csv('../Assets/Tableau/faves_religion.csv')\n",
      "    \n",
      "\n",
      "\n",
      "# ### Religion seriousness\n",
      "\n",
      "# In[61]:\n",
      "\n",
      "levels = []\n",
      "for religion in tf.Xreligion.value_counts().index:\n",
      "    try:\n",
      "        level = religion.split('and ', 1)[1]\n",
      "    except: continue\n",
      "    if level not in levels:\n",
      "        levels.append(level)\n",
      "\n",
      "def level_encoder(rel):\n",
      "    try:\n",
      "        for level in levels:\n",
      "            if rel.find(level) >0:\n",
      "                return level\n",
      "    except:\n",
      "        return ''\n",
      "\n",
      "tf['Xreligiousness'] = tf.Xreligion.apply(level_encoder)\n",
      "\n",
      "\n",
      "# In[62]:\n",
      "\n",
      "df = pd.DataFrame()\n",
      "df_religiousness = pd.DataFrame(index=[0], columns=['tfidf', 'label'])\n",
      "for level in levels:\n",
      "    # Compute mean values for each level of religiousness\n",
      "    df2 = tf[tf['Xreligiousness']==level]\n",
      "    df[level] = df2.iloc[:,:length].mean(axis=0)\n",
      "# Compute averages\n",
      "df['avg'] = df.mean(axis=1)\n",
      "\n",
      "for level in levels:\n",
      "    # sort by diff for each category\n",
      "    df['%s_diff' %level] = df[level] - df['avg']\n",
      "    df.sort_values('%s_diff' % level, inplace=True, ascending=False)\n",
      "    # Save top 50]to level_dic\n",
      "    level_list = ''\n",
      "    for word in df.index[:50]:\n",
      "        level_list = level_list + word + ', '\n",
      "    all_lists = all_lists + '\\n\\n%s\\n\\n' %level + level_list\n",
      "    # Save top 20 to df\n",
      "    df2 = pd.DataFrame(df[level].head(20))\n",
      "    df2.columns = ['tfidf']\n",
      "    df2['label'] = level\n",
      "    \n",
      "    df_religiousness = pd.concat([df_religiousness, df2], axis=0)\n",
      "\n",
      "\n",
      "df_religiousness.to_csv('../Assets/Tableau/faves_religiousness.csv')\n",
      "\n",
      "\n",
      "# ### Explore Diet\n",
      "\n",
      "# In[63]:\n",
      "\n",
      "tf.Xdiet.value_counts()\n",
      "\n",
      "# ignore anything and other\n",
      "# just look for vegetarian, vegan, kosher, halal\n",
      "\n",
      "def diet_encoder(diet):\n",
      "    try:\n",
      "        if diet.find('vegan') >= 0:\n",
      "            return 'vegan'\n",
      "        elif diet.find('vegetarian') >= 0:\n",
      "            return 'vegetarian'\n",
      "        elif diet.find('kosher') >= 0:\n",
      "            return 'kosher'\n",
      "        elif diet.find('halal') >= 0:\n",
      "            return 'halal'\n",
      "        else:\n",
      "            return ''\n",
      "    except:\n",
      "        return ''\n",
      "    \n",
      "tf.Xdiet = tf.Xdiet.apply(diet_encoder)\n",
      "\n",
      "\n",
      "# In[64]:\n",
      "\n",
      "# Exclude '' from diets\n",
      "diets = tf.Xdiet.value_counts().index[1:]\n",
      "\n",
      "df = pd.DataFrame()\n",
      "df_diet = pd.DataFrame(index=[0], columns=['tfidf', 'label'])\n",
      "for diet in diets:\n",
      "    # Compute mean values for each level of religiousness\n",
      "    df2 = tf[tf.Xdiet==diet]\n",
      "    df[diet] = df2.iloc[:,:length].mean(axis=0)\n",
      "# Compute averages\n",
      "df['avg'] = df.mean(axis=1)\n",
      "\n",
      "for diet in diets:\n",
      "    # sort by diff for each category\n",
      "    df['%s_diff' %diet] = df[diet] - df['avg']\n",
      "    df.sort_values('%s_diff' % diet, inplace=True, ascending=False)\n",
      "    # Save top 50]to level_dic\n",
      "    diet_list = ''\n",
      "    for word in df.index[:50]:\n",
      "        diet_list = diet_list + word + ', '\n",
      "    all_lists = all_lists + '\\n\\n%s\\n\\n' %diet + diet_list\n",
      "    # Save top 20 to df\n",
      "    df2 = pd.DataFrame(df[diet].head(15))\n",
      "    df2.columns = ['tfidf']\n",
      "    df2['label'] = diet\n",
      "    \n",
      "    df_diet = pd.concat([df_diet, df2], axis=0)\n",
      "\n",
      "\n",
      "df_diet.to_csv('../Assets/Tableau/faves_diet.csv')\n",
      "\n",
      "\n",
      "# In[65]:\n",
      "\n",
      "# save all_lists to file ../Assets/Tableau/faves_all_lists.txt\n",
      "\n",
      "target = open('../Assets/Tableau/faves_all_lists.txt', 'w')\n",
      "\n",
      "target.write(all_lists)\n",
      "target.close()\n",
      "\n",
      "\n",
      "# In[66]:\n",
      "\n",
      "# compare labels w/ encoders vs. labels with dummies for overall correlations\n",
      "# write script to save dicts to text file\n",
      "\n",
      "\n",
      "# List top 50]lists here:\n",
      "# \n",
      "# \n",
      "\n",
      "# \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
