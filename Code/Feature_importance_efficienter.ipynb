{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "okc = pd.read_csv('../Assets/A/one_long_essay.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def denull(essay):\n",
    "    if type(essay) == float:\n",
    "        return ''\n",
    "    else: return essay\n",
    "    \n",
    "okc.essays = okc.essays.apply(denull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorized essays in 16.2227 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "vec = TfidfVectorizer(encoding='utf-8', stop_words='english', max_features=2000)\n",
    "tf = vec.fit_transform(okc.essays)\n",
    "print \"vectorized essays in %g seconds\" %(time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf = pd.DataFrame(tf.toarray(), columns=vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save any features we might want to filter by to tf dataframe\n",
    "features = ['age', 'body_type', 'diet', 'drinks', 'drugs', 'education', 'ethnicity', \n",
    "           'height', 'income', 'job', 'offspring', 'orientation', 'pets', 'religion', \n",
    "            'sex', 'sign', 'smokes', 'speaks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for feature in features:\n",
    "    tf['X%s' %feature] = okc[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Handle some common conjunctions which get separated from words\n",
    "# leading to features like 'don' and 'll\n",
    "\n",
    "tf = tf.rename(columns = {'don':\"don't\", 'll':\"i'll\", 've':\"i've\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find top words by tf-idf score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_words = tf.iloc[:,:2000].mean(axis=0)\n",
    "mean_words.sort_values(inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add something to this for hue?\n",
    "mean_words[:60].to_csv('../Assets/Tableau/top_words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save a single string with top words for each category.  This list will be exported to a .txt file at end of script\n",
    "all_lists = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare word frequency for men vs. women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.674036979675\n"
     ]
    }
   ],
   "source": [
    "# Compute mean value of each of first 2000 columns for men\n",
    "t0 = time()\n",
    "mdf = tf[tf.Xsex=='m']\n",
    "df = pd.DataFrame(mdf.iloc[:,:2000].mean(axis=0), columns = ['m'])\n",
    "print time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.482522964478\n"
     ]
    }
   ],
   "source": [
    "# Compute mean value of each of first 2000 columns for women\n",
    "t0 = time()\n",
    "fdf = tf[tf.Xsex == 'f']\n",
    "df['f'] = fdf.iloc[:,:2000].mean(axis=0)\n",
    "print time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['diff'] = df['m']-df['f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.sort_values('diff', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save top 200 words for women and men for report\n",
    "women_list = ''\n",
    "for word in df.index[:200]:\n",
    "    women_list = women_list + word + ', '\n",
    "    \n",
    "men_list = ''\n",
    "# Write men_list in reverse order so most popular words are on top\n",
    "for i in range(-1, -200, -1):\n",
    "    men_list = men_list + df.index[i] + ', '\n",
    "    \n",
    "all_lists = 'Women \\n \\n' + women_list + '\\n\\n Men \\n\\n' + men_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save top 30 from each cat\n",
    "# women\n",
    "df.sort_values('diff', inplace=True)\n",
    "f = pd.DataFrame(df.head(30)['f'])\n",
    "f.columns = ['tfidf']\n",
    "f['label'] = 'female'\n",
    "\n",
    "# men\n",
    "df.sort_values('diff', inplace=True, ascending=False)\n",
    "m = pd.DataFrame(df.head(30)['m'])\n",
    "m.columns = ['tfidf']\n",
    "m['label'] = 'male'\n",
    "\n",
    "\n",
    "df_sex = pd.concat([m, f], axis=0)\n",
    "\n",
    "df_sex.to_csv('../Assets/Tableau/df_sex.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare word frequency for social drinkers vs. heavy drinkers vs. non drinkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.851545095444\n"
     ]
    }
   ],
   "source": [
    "# Compare word frequency for social drinkers vs. heavy drinkers vs. non drinkers\n",
    "\n",
    "# Compute mean value of each of first 2000 columns for social drinks\n",
    "t0 = time()\n",
    "ddf = tf[tf.Xdrinks=='socially']\n",
    "df = pd.DataFrame(ddf.iloc[:,:2000].mean(axis=0), columns = ['social'])\n",
    "print time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.359460115433\n"
     ]
    }
   ],
   "source": [
    "# Compute mean value of each of first 2000 columns for non-drinkers\n",
    "t0 = time()\n",
    "ddf = tf.query(\"Xdrinks == 'rarely'|Xdrinks == 'not at all'\")\n",
    "df['non-drinker'] = ddf.iloc[:,:2000].mean(axis=0)\n",
    "print time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.189160823822\n"
     ]
    }
   ],
   "source": [
    "# Compute mean value of each of first 2000 columns for heavy drinkers\n",
    "t0 = time()\n",
    "ddf = tf.query(\"Xdrinks == 'often'|Xdrinks == 'very often'|Xdrinks == 'desperately'\")\n",
    "df['heavy'] = ddf.iloc[:,:2000].mean(axis=0)\n",
    "print time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['avg'] = df.mean(axis=1)\n",
    "# Compute differences between social drinkers' values and other categories\n",
    "df['nd_diff'] = df['non-drinker'] - df['avg']\n",
    "df['h_diff'] = df['heavy'] - df['avg']\n",
    "df['s_diff'] = df['social'] - df['avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save top 200 words for heavy, social, and non-drinkers for report\n",
    "# heavy drinkers:\n",
    "df.sort_values('h_diff', ascending=False, inplace=True)\n",
    "\n",
    "heavy_list = ''\n",
    "for word in df.index[:200]:\n",
    "    heavy_list = heavy_list + word + ', '\n",
    "\n",
    "# social drinkers:\n",
    "df.sort_values('s_diff', ascending=False, inplace=True)\n",
    "\n",
    "social_list = ''\n",
    "for word in df.index[:200]:\n",
    "    social_list = social_list + word + ', '\n",
    "    \n",
    "# non-drinkers:\n",
    "df.sort_values('nd_diff', ascending=False, inplace=True)\n",
    "\n",
    "non_list = ''\n",
    "for word in df.index[:200]:\n",
    "    non_list = non_list + word + ', '\n",
    "    \n",
    "all_lists = all_lists +  '\\n\\nDrink heavily \\n \\n' +  heavy_list + '\\n\\nDrink socially \\n\\n' + social_list + '\\n\\nDo not drink regularly \\n\\n'+ non_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save top 18 from each cat\n",
    "# non-drinkers first\n",
    "df.sort_values('nd_diff', inplace=True, ascending=False)\n",
    "nd = pd.DataFrame(df.head(18)['non-drinker'])\n",
    "nd.columns = ['tfidf']\n",
    "nd['label'] = 'non-drinker'\n",
    "\n",
    "# social drinkers\n",
    "df.sort_values('s_diff', inplace=True, ascending=False)\n",
    "sd = pd.DataFrame(df.head(18)['social'])\n",
    "sd.columns = ['tfidf']\n",
    "sd['label'] = 'social'\n",
    "\n",
    "# heavy drinkers\n",
    "df.sort_values('h_diff', inplace=True, ascending=False)\n",
    "hd = pd.DataFrame(df.head(18)['heavy'])\n",
    "hd.columns = ['tfidf']\n",
    "hd['label'] = 'heavy'\n",
    "\n",
    "df_drinks = pd.concat([nd, sd, hd], axis=0)\n",
    "\n",
    "df_drinks.to_csv('../Assets/Tableau/df_drinks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore word choice by age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116b0ce50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(okc.age, 50, normed=1, facecolor='green', alpha=0.75)\n",
    "plt.axis([15, 80, 0, .1])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compare under 30 to over 30\n",
    "\n",
    "def age_encoder(age):\n",
    "    if age ==0:\n",
    "        return np.nan\n",
    "    elif age < 30:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "tf.Xage = tf.Xage.apply(age_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.699970960617\n",
      "1.51530790329\n"
     ]
    }
   ],
   "source": [
    "# Compare word frequency for under 30 vs. over 30\n",
    "\n",
    "# Compute mean value of each of first 2000 columns for over 30\n",
    "t0 = time()\n",
    "odf = tf[tf.Xage==1]\n",
    "df = pd.DataFrame(odf.iloc[:,:2000].mean(axis=0), columns = ['>30'])\n",
    "print time()-t0\n",
    "\n",
    "# Compute mean value of each of first 2000 columns for under 30\n",
    "ydf = tf[tf.Xage == 0]\n",
    "df['<30'] = ydf.iloc[:,:2000].mean(axis=0)\n",
    "print time()-t0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['diff'] = df['>30']-df['<30']\n",
    "df.sort_values('diff', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save top 200 words for people under and over 30\n",
    "# older people:\n",
    "df.sort_values('diff', ascending=False, inplace=True)\n",
    "\n",
    "older_list = ''\n",
    "for word in df.index[:200]:\n",
    "    older_list = older_list + word + ', '\n",
    "\n",
    "# younger people\n",
    "younger_list = ''\n",
    "# Write older_list in reverse order so most popular words are on top\n",
    "for i in range(-1, -200, -1):\n",
    "    younger_list = younger_list + df.index[i] + ', '\n",
    "    \n",
    "all_lists = all_lists + '\\n\\nOver 30 \\n \\n' + older_list + '\\n\\nUnder 30 \\n\\n' + younger_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save top 30 from each cat\n",
    "# n.b terms younger and older are strictly relative\n",
    "\n",
    "# younger\n",
    "df.sort_values('diff', inplace=True)\n",
    "y = pd.DataFrame(df.head(30)['<30'])\n",
    "y.columns = ['tfidf']\n",
    "y['label'] = '<30'\n",
    "\n",
    "# older\n",
    "df.sort_values('diff', inplace=True, ascending=False)\n",
    "o = pd.DataFrame(df.head(30)['>30'])\n",
    "o.columns = ['tfidf']\n",
    "o['label'] = '>30'\n",
    "\n",
    "\n",
    "df_age = pd.concat([y, o], axis=0)\n",
    "\n",
    "df_age.to_csv('../Assets/Tableau/df_age.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare drug users and non-users\n",
    "exclude those who don't report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drug_encoder(drugs):\n",
    "    if drugs == 'never':\n",
    "        return 0\n",
    "    elif drugs == 'sometimes' or drugs == 'often':\n",
    "        return 1\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "tf.Xdrugs = tf.Xdrugs.apply(drug_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.25930714607\n",
      "2.9483859539\n"
     ]
    }
   ],
   "source": [
    "# Compute mean value of each of first 2000 columns for drug users\n",
    "t0 = time()\n",
    "udf = tf[tf.Xdrugs==1]\n",
    "df = pd.DataFrame(odf.iloc[:,:2000].mean(axis=0), columns = ['users'])\n",
    "print time()-t0\n",
    "\n",
    "# Compute mean value of each of first 2000 columns for non-users\n",
    "ydf = tf[tf.Xdrugs == 0]\n",
    "df['non-users'] = ydf.iloc[:,:2000].mean(axis=0)\n",
    "print time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['diff'] = df['users']-df['non-users']\n",
    "df.sort_values('diff', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save top 200 words for users and non-users\n",
    "# users:\n",
    "df.sort_values('diff', ascending=False, inplace=True)\n",
    "\n",
    "non_user_list = ''\n",
    "for word in df.index[:200]:\n",
    "    non_user_list = non_user_list + word + ', '\n",
    "\n",
    "# non-users\n",
    "user_list = ''\n",
    "# Write older_list in reverse order so most popular words are on top\n",
    "for i in range(-1, -200, -1):\n",
    "    user_list = user_list + df.index[i] + ', '\n",
    "    \n",
    "all_lists = all_lists + '\\n\\nUse drugs \\n \\n' + non_user_list + '\\n\\nDo not use drugs \\n\\n' + user_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save top 30 from each cat\n",
    "# non-users\n",
    "\n",
    "n = pd.DataFrame(df.head(30)['non-users'])\n",
    "n.columns = ['tfidf']\n",
    "n['label'] = 'non-users'\n",
    "\n",
    "# users\n",
    "\n",
    "m = pd.DataFrame(df.tail(30)['users'])\n",
    "m.columns = ['tfidf']\n",
    "m['label'] = 'users'\n",
    "\n",
    "\n",
    "df_drugs = pd.concat([m, n], axis=0)\n",
    "\n",
    "df_drugs.to_csv('../Assets/Tableau/df_drugs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAEACAYAAAAX9rnOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKx2Hk5mZlY7DyczMSsfhZGZmpfP/AfF/lwELWuQ+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11918aa10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(tf.Xincome[tf.Xincome != -1], 50, normed=1, facecolor='green', alpha=0.75)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Divide income income into <50k, 50-100k, >100k\n",
    "\n",
    "def income_encoder(income):\n",
    "    if income == -1:\n",
    "        return -1\n",
    "    elif income <= 50000:\n",
    "        return 0\n",
    "    elif income <= 100000:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "tf.Xincome = tf.Xincome.apply(income_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19762301445\n",
      "0.105547904968\n",
      "0.0465598106384\n"
     ]
    }
   ],
   "source": [
    "# Compare word frequency for different income levels\n",
    "\n",
    "# Compute mean value of each of first 2000 columns for lower income\n",
    "t0 = time()\n",
    "pdf = tf[tf.Xincome==0]\n",
    "df = pd.DataFrame(pdf.iloc[:,:2000].mean(axis=0), columns = ['<50k'])\n",
    "print time()-t0\n",
    "\n",
    "# Compute mean value of each of first 2000 columns for middle income\n",
    "t0 = time()\n",
    "mdf = tf[tf.Xincome==1]\n",
    "df['50-100k'] = mdf.iloc[:,:2000].mean(axis=0)\n",
    "print time()-t0\n",
    "\n",
    "# Compute mean value of each of first 2000 columns for highest income\n",
    "t0 = time()\n",
    "rdf = tf[tf.Xincome==2]\n",
    "df['>100k'] = rdf.iloc[:,:2000].mean(axis=0)\n",
    "print time()-t0\n",
    "\n",
    "\n",
    "# Compute differences between each income category and overall average\n",
    "df['avg'] = df.mean(axis=1)\n",
    "df['r_diff'] = df['>100k'] - df['avg']\n",
    "df['p_diff'] = df['<50k'] - df['avg']\n",
    "df['m_diff'] = df['50-100k'] - df['avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save lists for each income bracket\n",
    "\n",
    "df.sort_values('r_diff', ascending=False, inplace=True)\n",
    "\n",
    "upper_list = ''\n",
    "for word in df.index[:200]:\n",
    "    upper_list = upper_list + word + ', '\n",
    "    \n",
    "df.sort_values('m_diff', ascending=False, inplace=True)\n",
    "\n",
    "mid_list = ''\n",
    "for word in df.index[:200]:\n",
    "    mid_list = mid_list + word + ', '\n",
    "    \n",
    "\n",
    "df.sort_values('p_diff', ascending=False, inplace=True)    \n",
    "lower_list = ''\n",
    "for word in df.index[:200]:\n",
    "    lower_list = lower_list + word + ', '\n",
    "\n",
    "all_lists = all_lists + '\\n\\nMake over 100k annually \\n \\n' + upper_list + '\\n\\nMake 50-100k annually\\n\\n' + mid_list+ '\\n\\nMake less than 50k annually'+lower_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save top 18 from each cat\n",
    "# richest first\n",
    "df.sort_values('r_diff', inplace=True, ascending=False)\n",
    "df2 = pd.DataFrame(df.head(18)['>100k'])\n",
    "df2.columns = ['tfidf']\n",
    "df2['label'] = '> 100k'\n",
    "\n",
    "# middle income\n",
    "df.sort_values('m_diff', inplace=True, ascending=False)\n",
    "df3 = pd.DataFrame(df.head(18)['50-100k'])\n",
    "df3.columns = ['tfidf']\n",
    "df3['label'] = '50 - 100k'\n",
    "\n",
    "# lower income\n",
    "df.sort_values('p_diff', inplace=True, ascending=False)\n",
    "df4 = pd.DataFrame(df.head(18)['<50k'])\n",
    "df4.columns = ['tfidf']\n",
    "df4['label'] = '< 50k'\n",
    "\n",
    "df_income = pd.concat([df2, df3, df4], axis=0)\n",
    "df_income.to_csv('../Assets/Tableau/df_income.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare dog and cat people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate dummy columns for likes dogs and likes cats\n",
    "# will be some overlap since not mutually exclusive\n",
    "\n",
    "def mask_dogs(pets):\n",
    "    # catches 'has dogs' or 'likes dogs'\n",
    "    try:\n",
    "        if pets.find('dogs') > -1:\n",
    "            if pets.find('dislikes dogs') == -1:\n",
    "                return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "def mask_cats(pets):\n",
    "    try:\n",
    "        if pets.find('cats') > -1:\n",
    "            if pets.find('dislikes cats') == -1:\n",
    "                return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "tf['Xdogs'] = tf.Xpets.apply(mask_dogs)\n",
    "tf['Xcats'] = tf.Xpets.apply(mask_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.24761986732\n",
      "2.73856282234\n"
     ]
    }
   ],
   "source": [
    "# find mean scores for dog people\n",
    "\n",
    "t0 = time()\n",
    "ddf = tf[tf.Xdogs==1]\n",
    "df = pd.DataFrame(ddf.iloc[:,:2000].mean(axis=0), columns = ['dogs'])\n",
    "print time()-t0\n",
    "\n",
    "# find mean scores for cat people\n",
    "cdf = tf[tf.Xcats == 1]\n",
    "df['cats'] = cdf.iloc[:,:2000].mean(axis=0)\n",
    "print time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['diff'] = df['dogs'] - df['cats']\n",
    "df.sort_values('diff', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove cat, cats, dog and dogs from this list since they don't contribute insight\n",
    "df = df.drop(['cat', 'cats', 'dog', 'dogs'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save top 200 words for cats and dogs for report\n",
    "cat_list = ''\n",
    "for word in df.index[:200]:\n",
    "    cat_list = cat_list + word + ', '\n",
    "    \n",
    "dog_list = ''\n",
    "# Write dog_list in reverse order so most popular words are on top\n",
    "for i in range(-1, -200, -1):\n",
    "    dog_list = dog_list + df.index[i] + ', '\n",
    "    \n",
    "all_lists = all_lists + '\\n\\nLike cats\\n \\n' + cat_list + '\\n\\nLike dogs \\n\\n' + dog_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save top 30 from each cat\n",
    "# cats\n",
    "\n",
    "n = pd.DataFrame(df.head(30)['cats'])\n",
    "n.columns = ['tfidf']\n",
    "n['label'] = 'cats'\n",
    "\n",
    "# men\n",
    "\n",
    "m = pd.DataFrame(df.tail(30)['dogs'])\n",
    "m.columns = ['tfidf']\n",
    "m['label'] = 'dogs'\n",
    "\n",
    "\n",
    "df_drugs = pd.concat([m, n], axis=0)\n",
    "\n",
    "df_drugs.to_csv('../Assets/Tableau/df_pets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore word choice by education\n",
    "\n",
    "college grad? 1 or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ed_encoder(ed):\n",
    "    # a person is a college grad if they either \"graduated from college/university\"\n",
    "    # or mention law school, med, school, masters program or ph. d program (all instances of the word program are graduate )\n",
    "    try:\n",
    "        if ed == 'graduated from college/university' or ed.find('law') >= 0 or ed.find('med') >= 0 or ed.find('program') >= 0:\n",
    "            return 1\n",
    "        # space camp answers are facetious and must be excluded\n",
    "        # BTW I am in space camp right now\n",
    "        elif ed.find('space camp') >= 0:\n",
    "            return np.nan\n",
    "        else: return 0\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "tf.Xeducation = tf.Xeducation.apply(ed_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.24032902718\n",
      "2.78602600098\n"
     ]
    }
   ],
   "source": [
    "# Compare word frequency for college educated vs. not college\n",
    "\n",
    "# Compute mean value of each of first 2000 columns for college\n",
    "t0 = time()\n",
    "df2 = tf[tf.Xage==1]\n",
    "df = pd.DataFrame(df2.iloc[:,:2000].mean(axis=0), columns = ['grad'])\n",
    "print time()-t0\n",
    "\n",
    "# Compute mean value of each of first 2000 columns for under 30\n",
    "df2 = tf[tf.Xage == 0]\n",
    "df['non-grad'] = df2.iloc[:,:2000].mean(axis=0)\n",
    "print time()-t0\n",
    "\n",
    "df['diff'] = df['grad'] - df['non-grad']\n",
    "df.sort_values('diff', inplace=True)\n",
    "\n",
    "# Save top 200 words for grads and non-grads for report\n",
    "non_grad_list = ''\n",
    "for word in df.index[:200]:\n",
    "    non_grad_list = non_grad_list + word + ', '\n",
    "    \n",
    "grad_list = ''\n",
    "# Write grad_list in reverse order so most popular words are on top\n",
    "for i in range(-1, -200, -1):\n",
    "    grad_list = grad_list + df.index[i] + ', '\n",
    "\n",
    "# Save top 200's lists to all_lists\n",
    "all_lists =  all_lists + '\\n\\nGraduated College\\n \\n' + grad_list + '\\n\\nDid Not Graduate College\\n\\n' + non_grad_list\n",
    "\n",
    "# Save top 30 from each cat\n",
    "# non-grads\n",
    "\n",
    "n = pd.DataFrame(df.head(30)['non-grad'])\n",
    "n.columns = ['tfidf']\n",
    "n['label'] = 'non-grads'\n",
    "\n",
    "# grads\n",
    "df.sort_values('diff', inplace=True, ascending=False)\n",
    "g = pd.DataFrame(df.head(30)['grad'])\n",
    "g.columns = ['tfidf']\n",
    "g['label'] = 'grads'\n",
    "\n",
    "\n",
    "df_ed = pd.concat([n, g], axis=0)\n",
    "\n",
    "df_ed.to_csv('../Assets/Tableau/df_ed.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore word choice by ethnicity\n",
    "\n",
    "options are: asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin, white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# It will be more efficient to encode dummies for each ethnic group than to search each entry\n",
    "# People who list multiple ethnicities will count for all ethnicities listed\n",
    "\n",
    "# write encoder for each ethnicity\n",
    "\n",
    "groups = ['asian', 'middle eastern', 'black', 'native american', 'indian', 'pacific islander', 'hispanic / latin', 'white']\n",
    "\n",
    "for ethnicity in groups:\n",
    "    def ethnicity_encoder(eth):\n",
    "        global ethnicity\n",
    "        try:\n",
    "            if eth.find(ethnicity) >= 0:\n",
    "                return 1\n",
    "            else: return 0\n",
    "        except:\n",
    "            return 0\n",
    "        \n",
    "    tf['X%s' %ethnicity] = tf.Xethnicity.apply(ethnicity_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.219777107239\n",
      "0.034961938858\n",
      "0.0967180728912\n",
      "0.0436480045319\n",
      "0.0523920059204\n",
      "0.0620038509369\n",
      "0.12365603447\n",
      "1.07361698151\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame(index=tf.columns[:2000])\n",
    "# Compute mean value of each of first 2000 columns for each ethnic group\n",
    "for ethnicity in groups:\n",
    "    t0 = time()\n",
    "    df2 = tf[tf['X%s' %ethnicity] == 1]\n",
    "    df[ethnicity] = pd.DataFrame(df2.iloc[:,:2000].mean(axis=0))\n",
    "    print time()-t0\n",
    "    \n",
    "df['avg'] = df.mean(axis=1)\n",
    "\n",
    "for ethnicity in groups:\n",
    "    df['%s_diff' %ethnicity] = df[ethnicity] - df['avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List top 100 words for each ethnicity\n",
    "\n",
    "\n",
    "# Fill string for each ethnicity with top words\n",
    "for ethnicity in groups:\n",
    "    df.sort_values('%s_diff' %ethnicity, ascending=False, inplace=True)\n",
    "    \n",
    "    eth_list = ''\n",
    "    for word in df.index[:100]:\n",
    "        eth_list = eth_list + word + ', '\n",
    "    all_lists = all_lists + '\\n\\n%s\\n\\n' %ethnicity + eth_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# There are 8 different ethnic groups available\n",
    "# Tableau does well with about 50 to 60 words for packed bubbles\n",
    "# Take top 7 words for each ethnicity\n",
    "\n",
    "# Drop words asian, middle, eastern, indian, and india as they are top ranking words but redundant with categories\n",
    "\n",
    "df.drop(['asian', 'middle', 'eastern', 'indian', 'india'], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# must have at least one row in dataframe in order to use pd.concat\n",
    "df_ethnicity = pd.DataFrame(index=[0], columns=['tfidf', 'label'])\n",
    "\n",
    "for ethnicity in groups:\n",
    "    # Save top 7 words for each ethnicity\n",
    "    df.sort_values('%s_diff' %ethnicity, ascending=False, inplace=True)\n",
    "    df3 = pd.DataFrame(df.head(7)[ethnicity])\n",
    "    df3.columns=['tfidf']\n",
    "    df3['label'] = ethnicity\n",
    "    \n",
    "    df_ethnicity = pd.concat([df_ethnicity, df3], axis=0)\n",
    "    \n",
    "# drop dummy row from top\n",
    "df_ethnicity.drop(0, axis=0, inplace=True)\n",
    "\n",
    "df_ethnicity.to_csv('../Assets/Tableau/df_ethnicity.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.151314020157\n",
      "0.122050046921\n",
      "0.141023159027\n",
      "0.115347862244\n",
      "0.124876022339\n",
      "0.0913069248199\n",
      "0.103110074997\n",
      "0.0854620933533\n",
      "0.081463098526\n",
      "0.0817778110504\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame(index=tf.columns[:2000])\n",
    "df_jobs = pd.DataFrame(index=[0], columns=['tfidf', 'label'])\n",
    "job_dic = {}\n",
    "# Most popular job category is \"other\"  Exclude that\n",
    "for job in tf.Xjob.value_counts()[1:11].index:\n",
    "    # Save a column of dummies for each job category\n",
    "    def job_encoder(career):\n",
    "        global job\n",
    "        try:\n",
    "            if career.find(job) >= 0:\n",
    "                return 1\n",
    "            else: return 0\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    tf['X%s' %job] = tf.Xjob.apply(job_encoder)\n",
    "\n",
    "    # Compute mean tfidf scores for job type\n",
    "    t0 = time()\n",
    "    df2 = tf[tf['X%s' %job] == 1]\n",
    "    df[job] = pd.DataFrame(df2.iloc[:,:2000].mean(axis=0))\n",
    "    print time()-t0\n",
    "    \n",
    "# Compute overall mean tfidf scores\n",
    "df['avg'] = df.mean(axis=1)\n",
    "\n",
    "    \n",
    "for job in tf.Xjob.value_counts()[1:11].index: \n",
    "    # compute diff between scores for each job and overall mean\n",
    "    df['%s_diff' %job] = df[job] - df['avg']    \n",
    "    \n",
    "\n",
    "    # sort by job\n",
    "    # save top 100 words asfor each job\n",
    "    # save top 6 words with tfidf scores and labels to df_jobs\n",
    "    job_list = ''\n",
    "    df.sort_values('%s_diff' %job, ascending=False, inplace=True)\n",
    "    # save top 200 words to reserved string in job_dic\n",
    "    for word in df.index[:100]:\n",
    "        job_list = job_list + word + ', '\n",
    "    \n",
    "    all_lists = all_lists + '\\n\\n%s\\n\\n' %job + job_list\n",
    "        \n",
    "    # Save top 6 words to df_jobs\n",
    "    df.sort_values('%s_diff' %job, ascending=False, inplace=True)\n",
    "    \n",
    "    df3 = pd.DataFrame(df.head(6)[job])\n",
    "    df3.columns=['tfidf']\n",
    "    df3['label'] = job\n",
    "    \n",
    "    df_jobs = pd.concat([df_jobs, df3], axis=0)\n",
    "    \n",
    "# drop dummy row from top\n",
    "df_jobs.drop(0, axis=0, inplace=True)\n",
    "\n",
    "df_jobs.to_csv('../Assets/Tableau/df_jobs.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at sexual orientation\n",
    "Break down by gender as well to account for different cultures in queer community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  app.launch_new_instance()\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:8: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:13: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:18: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:22: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:26: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "# Compute mean value of each of first 2000 columns for gay men\n",
    "\n",
    "df2 = tf[tf.Xsex=='m'][tf.Xorientation=='gay']\n",
    "df = pd.DataFrame(df2.iloc[:,:2000].mean(axis=0), columns = ['gay men'])\n",
    "\n",
    "\n",
    "# Compute mean value of each of first 2000 columns for bi men\n",
    "df2 = tf[tf.Xsex=='m'][tf.Xorientation=='bisexual']\n",
    "df['bi men'] = df2.iloc[:,:2000].mean(axis=0)\n",
    "\n",
    "\n",
    "# Compute mean values for straight men\n",
    "df2 = tf[tf.Xsex=='m'][tf.Xorientation=='straight']\n",
    "df['straight men'] = df2.iloc[:,:2000].mean(axis=0)\n",
    "\n",
    "\n",
    "# Compute mean values for gay women\n",
    "df2 = tf[tf.Xsex=='f'][tf.Xorientation=='gay']\n",
    "df['gay women'] = df2.iloc[:,:2000].mean(axis=0)\n",
    "\n",
    "# Compute mean values for bi women\n",
    "df2 = tf[tf.Xsex=='f'][tf.Xorientation=='bisexual']\n",
    "df['bi women'] = df2.iloc[:,:2000].mean(axis=0)\n",
    "\n",
    "# Compute mean values for straight women\n",
    "df2 = tf[tf.Xsex=='f'][tf.Xorientation=='straight']\n",
    "df['straight women'] = df2.iloc[:,:2000].mean(axis=0)\n",
    "\n",
    "\n",
    "df['avg'] = df.mean(axis=1)\n",
    "df['gay men diff'] = df['gay men'] - df.avg\n",
    "df['bi men diff'] = df['bi men'] - df.avg\n",
    "df['straight men diff'] = df['straight men'] - df.avg\n",
    "df['gay women diff'] = df['gay women'] - df.avg\n",
    "df['bi women diff'] = df['bi women'] - df.avg\n",
    "df['straight women diff'] = df['straight women'] - df.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save word lists\n",
    "df_orientation = pd.DataFrame(index=[0], columns=['tfidf', 'label'])\n",
    "\n",
    "for group in df.columns[:6]:\n",
    "    df.sort_values('%s diff' %group, ascending=False, inplace=True)\n",
    "    group_list = ''\n",
    "    for word in df.index[:100]:\n",
    "        group_list = group_list + word + ', '\n",
    "    all_lists = all_lists + '\\n\\n%s\\n\\n' %group + group_list\n",
    "# Save df for Tableau with top 10 for each category\n",
    "    df2 = pd.DataFrame(df[group].head(10))\n",
    "    df2.columns = ['tfidf']\n",
    "    df2['label'] = group\n",
    "\n",
    "    \n",
    "    df_orientation = pd.concat([df_orientation, df2], axis=0)\n",
    "    \n",
    "df_orientation.drop(0, axis=0, inplace=True)\n",
    "\n",
    "df_orientation.to_csv('../Assets/Tableau/df_orientation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Explore Religion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list religions \n",
    "religions = []\n",
    "for religion in tf.Xreligion.value_counts().index:\n",
    "    rel = religion.split(' ', 1)[0]\n",
    "    if rel not in religions:\n",
    "        religions.append(rel)\n",
    "religions = filter(lambda x: x != 'other', religions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Encode dummies for each religion\n",
    "# rel is individual person's religion string \"Christianity and very serious about it\"\n",
    "# religion is each group \"Christianity\"\n",
    "\n",
    "tf.Xreligion.replace(np.nan, '', inplace=True)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df_religion = pd.DataFrame(index=[0], columns=['tfidf', 'label'])\n",
    "\n",
    "for religion in religions:\n",
    "    tf['X%s' %religion] = tf.Xreligion.apply(lambda rel: 1 if rel.split(' ', 1)[0] == religion else 0)\n",
    "\n",
    "    # Compute mean values for each religion\n",
    "    df2 = tf[tf['X%s' %religion]==1]\n",
    "    df[religion] = df2.iloc[:,:2000].mean(axis=0)\n",
    "    \n",
    "# Compute mean for each word across religons\n",
    "df['avg'] = df.mean(axis=1)\n",
    "\n",
    "for religion in religions:\n",
    "    df['%s_diff' %religion] = df[religion] -df['avg']\n",
    "\n",
    "    # Save top 200 words for each religion as string\n",
    "    df.sort_values('%s_diff' % religion, inplace=True, ascending=False)\n",
    "    \n",
    "    rel_list = ''\n",
    "    for word in df.index[:100]:\n",
    "        rel_list = rel_list + word + ', '\n",
    "        \n",
    "    all_lists = all_lists + '\\n\\n%s\\n\\n' %religion + rel_list\n",
    "    \n",
    "    # Save top 7 words for each religon as df for Tableau\n",
    "    df2 = pd.DataFrame(df[religion].head(7))\n",
    "    df2.columns = ['tfidf']\n",
    "    df2['label'] = religion\n",
    "    \n",
    "    df_religion = pd.concat([df_religion, df2], axis=0)\n",
    "    \n",
    "df_religion.drop(0, axis=0, inplace=True)\n",
    "df_religion.to_csv('../Assets/Tableau/df_religion.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Religion seriousness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "levels = []\n",
    "for religion in tf.Xreligion.value_counts().index:\n",
    "    try:\n",
    "        level = religion.split('and ', 1)[1]\n",
    "    except: continue\n",
    "    if level not in levels:\n",
    "        levels.append(level)\n",
    "\n",
    "def level_encoder(rel):\n",
    "    try:\n",
    "        for level in levels:\n",
    "            if rel.find(level) >0:\n",
    "                return level\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "tf['Xreligiousness'] = tf.Xreligion.apply(level_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df_religiousness = pd.DataFrame(index=[0], columns=['tfidf', 'label'])\n",
    "for level in levels:\n",
    "    # Compute mean values for each level of religiousness\n",
    "    df2 = tf[tf['Xreligiousness']==level]\n",
    "    df[level] = df2.iloc[:,:2000].mean(axis=0)\n",
    "# Compute averages\n",
    "df['avg'] = df.mean(axis=1)\n",
    "\n",
    "for level in levels:\n",
    "    # sort by diff for each category\n",
    "    df['%s_diff' %level] = df[level] - df['avg']\n",
    "    df.sort_values('%s_diff' % level, inplace=True, ascending=False)\n",
    "    # Save top 200 to level_dic\n",
    "    level_list = ''\n",
    "    for word in df.index[:200]:\n",
    "        level_list = level_list + word + ', '\n",
    "    all_lists = all_lists + '\\n\\n%s\\n\\n' %level + level_list\n",
    "    # Save top 20 to df\n",
    "    df2 = pd.DataFrame(df[level].head(20))\n",
    "    df2.columns = ['tfidf']\n",
    "    df2['label'] = level\n",
    "    \n",
    "    df_religiousness = pd.concat([df_religiousness, df2], axis=0)\n",
    "df_religiousness.drop(0, axis=0, inplace=True)\n",
    "\n",
    "df_religiousness.to_csv('../Assets/Tableau/df_religiousness.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Diet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.Xdiet.value_counts()\n",
    "\n",
    "# ignore anything and other\n",
    "# just look for vegetarian, vegan, kosher, halal\n",
    "\n",
    "def diet_encoder(diet):\n",
    "    try:\n",
    "        if diet.find('vegan') >= 0:\n",
    "            return 'vegan'\n",
    "        elif diet.find('vegetarian') >= 0:\n",
    "            return 'vegetarian'\n",
    "        elif diet.find('kosher') >= 0:\n",
    "            return 'kosher'\n",
    "        elif diet.find('halal') >= 0:\n",
    "            return 'halal'\n",
    "        else:\n",
    "            return ''\n",
    "    except:\n",
    "        return ''\n",
    "    \n",
    "tf.Xdiet = tf.Xdiet.apply(diet_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Exclude '' from diets\n",
    "diets = tf.Xdiet.value_counts().index[1:]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df_diet = pd.DataFrame(index=[0], columns=['tfidf', 'label'])\n",
    "for diet in diets:\n",
    "    # Compute mean values for each level of religiousness\n",
    "    df2 = tf[tf.Xdiet==diet]\n",
    "    df[diet] = df2.iloc[:,:2000].mean(axis=0)\n",
    "# Compute averages\n",
    "df['avg'] = df.mean(axis=1)\n",
    "\n",
    "for diet in diets:\n",
    "    # sort by diff for each category\n",
    "    df['%s_diff' %diet] = df[diet] - df['avg']\n",
    "    df.sort_values('%s_diff' % diet, inplace=True, ascending=False)\n",
    "    # Save top 100 to level_dic\n",
    "    diet_list = ''\n",
    "    for word in df.index[:100]:\n",
    "        diet_list = diet_list + word + ', '\n",
    "    all_lists = all_lists + '\\n\\n%s\\n\\n' %diet + diet_list\n",
    "    # Save top 20 to df\n",
    "    df2 = pd.DataFrame(df[diet].head(15))\n",
    "    df2.columns = ['tfidf']\n",
    "    df2['label'] = diet\n",
    "    \n",
    "    df_diet = pd.concat([df_diet, df2], axis=0)\n",
    "df_diet.drop(0, axis=0, inplace=True)\n",
    "\n",
    "df_diet.to_csv('../Assets/Tableau/df_diet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save all_lists to file ../Assets/Tableau/df_all_lists.txt\n",
    "\n",
    "target = open('../Assets/Tableau/df_all_lists.txt', 'w')\n",
    "\n",
    "target.write(all_lists)\n",
    "target.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compare labels w/ encoders vs. labels with dummies for overall correlations\n",
    "# write script to save dicts to text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List top 200 lists here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
