{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from bs4 import BeautifulSoup    \n",
    "import re\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find null values for target column and remove from rows from tf\n",
    "# outputs: target column, new tf matrix\n",
    "\n",
    "def denull(tfidf, df, target_col):\n",
    "    target = df[df[target_col].isnull()==False][target_col]\n",
    "    tf_target = tfidf.ix[target.index]\n",
    "    return (target, tf_target)\n",
    "\n",
    "# Convert tf to sparse matrix\n",
    "def sparse_df_to_array(tf_target):\n",
    "    num_rows = tf_target.shape[0]   \n",
    "\n",
    "    data = []\n",
    "    row = []\n",
    "    col = []\n",
    "\n",
    "    for i, col_name in enumerate(tf_target.columns):\n",
    "        if isinstance(tf_target[col_name], pd.SparseSeries):\n",
    "            column_index = tf_target[col_name].sp_index\n",
    "            if isinstance(column_index, BlockIndex):\n",
    "                column_index = column_index.to_int_index()\n",
    "\n",
    "            ix = column_index.indices\n",
    "            data.append(tf_target[col_name].sp_values)\n",
    "            row.append(ix)\n",
    "            col.append(len(tf_target[col_name].sp_values) * [i])\n",
    "        else:\n",
    "            data.append(tf_target[col_name].values)\n",
    "            row.append(np.array(range(0, num_rows)))\n",
    "            col.append(np.array(num_rows * [i]))\n",
    "\n",
    "    data_f = np.concatenate(data)\n",
    "    row_f = np.concatenate(row)\n",
    "    col_f = np.concatenate(col)\n",
    "\n",
    "    arr = sp.sparse.coo_matrix((data_f, (row_f, col_f)), tf_target.shape, dtype=np.float64)\n",
    "    return arr.tocsr()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# encoder must be a function\n",
    "\n",
    "def process(tfidf_matrix, df, target, encoder=lambda x:LabelEncoder().fit_transform(x)):\n",
    "    # denull tf and df\n",
    "    (target_col, target_tf) = denull(tf, okc, target)\n",
    "    # encode values\n",
    "    target_col = encoder(target_col)\n",
    "    # Make tf sparse\n",
    "    sparse_tf = sparse_df_to_array(target_tf)\n",
    "    # Initiate train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(sparse_tf, target_col)\n",
    "    return (X_train, X_test, y_train, y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test preprocessing function\n",
    "### Predict sex of user based on long essay (top 2000 words, stemmed, and tfidf vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test on sex column\n",
    "\n",
    "okc = pd.read_csv('../Assets/A/one_long_essay.csv')\n",
    "tf = pd.read_csv('../Assets/A/Tfidf_Variations/Long_Essay/top_2000_words_nomax_stemmed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = process(tf, okc, \"sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.722203002837\n"
     ]
    }
   ],
   "source": [
    "print metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.41      0.80      0.54      2954\n",
      "          1       0.93      0.70      0.80     11499\n",
      "\n",
      "avg / total       0.82      0.72      0.75     14453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print metrics.classification_report(y_pred, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
