{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rewrite code from Feature_importance_effficienter.ipynb to run on faves.csv instead of tfidf vectorized essays.\n",
    "\n",
    "# Skip first part of code as no tf-idf vectorization necessary\n",
    "# Save faves as 'tf' so remainder of code will run on it.\n",
    "\n",
    "# adjust indexing\n",
    "# tf.iloc[:,:2000] adjusted to appropriate feature length (currently 1046 but may be adjusted if I drop more titles)\n",
    "# save appropriate length as length\n",
    "# tf.iloc[:,:2000] become tf.iloc[:,:length]\n",
    "\n",
    "# change top_words.csv to top_faves.csv\n",
    "\n",
    "# change 'df' to 'faves' in FILENAMES ONLY to avoid saving over important files\n",
    "# e.g. df_drinks.to_csv('../Assets/Tableau/df_drinks.csv') becomes df_drinks.to_csv('../Assets/Tableau/faves_drinks.csv')\n",
    "\n",
    "# Time permitting, try redoing with cog\n",
    "\n",
    "# remove %matplotlib inline\n",
    "# works on .ipynb only\n",
    "\n",
    "# remove all lines that include a .drop.  Rows being dropped will not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Beginning of code is significantly different\n",
    "# Rewrite manually\n",
    "\n",
    "beginning = '''\n",
    "\n",
    "# This code is generated with Feature_importance_bbmf.ipynb\n",
    "# based on code from Feature_importance_efficienter.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import re\n",
    "\n",
    "okc = pd.read_csv('../Assets/A/one_long_essay.csv', index_col='Unnamed: 0')\n",
    "tf = pd.read_csv('../Assets/A/faves.csv', index_col='Unnamed: 0')\n",
    "\n",
    "### Drop problematic/questionable values from faves\n",
    "# Return to this section and expand as you identify new \"favorites\" that are most likely regex false positives in most cases.\n",
    "\n",
    "# Most references to \"love\" are not the 2015 3-d erotic film, but more likely to be \"I love Harry Potter!\"\n",
    "# \"Chocolat\" will be selected for those people whose favorite food is chocolate as well as those who enjoy th 2001 French film\n",
    "# Similarly, 'it', '...', 'yes', '2', 'i', 'the', 'currently' 'and', 'oh', 'etc', 'big' and 'eat', 'tron', and 'pi' are most likely not titles or even necessarily whole words.\n",
    "# 'Kurt Vonnegut' will select for a subset of 'Vonnegut' mentions.  Does not contribute new insight.\n",
    "# 'elf' will be picked up by any mention of 'self'\n",
    "# 'fiction' will pick up all mentions of non-fiction\n",
    "# 'up' is most likely not the amazing animated movie :-(\n",
    "# can I improve my regex so it only searches for whole words?\n",
    "# TRY THAT LATER!\n",
    "\n",
    "tf = tf.drop(['love', 'night', 'heat', 'rant', 'chocolat', 'it', '...', 'yes', '2', 'i', 'the', 'currently', 'and', 'oh', 'etc', 'big', 'eat', 'tron', 'the hangover', 'pi', 'kurt vonnegut', 'elf', 'fiction', 'up'], axis=1)\n",
    "length = tf.shape[1]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy and paste all code from Feature_importance_efficienter.ipynb\n",
    "# Try again later using cog for style points (plus to capture any updates to feature_importance_efficienter with each running)\n",
    "# For now I will skip commands of the form \"men_list\" that will run in ipynb but not in a .py file\n",
    "# ultimately I will remove these commands from notebook and save all outputs to .txt and .csv files only\n",
    "\n",
    "code = '''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "okc = pd.read_csv('../Assets/A/one_long_essay.csv', index_col='Unnamed: 0')\n",
    "\n",
    "def denull(essay):\n",
    "    if type(essay) == float:\n",
    "        return ''\n",
    "    else: return essay\n",
    "    \n",
    "okc.essays = okc.essays.apply(denull)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "t0 = time()\n",
    "vec = TfidfVectorizer(encoding='utf-8', stop_words='english', max_features=2000)\n",
    "tf = vec.fit_transform(okc.essays)\n",
    "print \"vectorized essays in %g seconds\" %(time()-t0)\n",
    "\n",
    "tf = pd.DataFrame(tf.toarray(), columns=vec.get_feature_names())\n",
    "\n",
    "# Save any features we might want to filter by to tf dataframe\n",
    "features = ['age', 'body_type', 'diet', 'drinks', 'drugs', 'education', 'ethnicity', \n",
    "           'height', 'income', 'job', 'offspring', 'orientation', 'pets', 'religion', \n",
    "            'sex', 'sign', 'smokes', 'speaks']\n",
    "            \n",
    "for feature in features:\n",
    "    tf['X%s' %feature] = okc[feature]\n",
    "    \n",
    "mean_words = tf.iloc[:,:2000].mean(axis=0)\n",
    "mean_words.sort_values(inplace=True, ascending=False)\n",
    "\n",
    "# add something to this for hue?\n",
    "mean_words[:60].to_csv('../Assets/Tableau/top_words.csv')\n",
    "\n",
    "# Compute mean value of each of first 2000 columns for men\n",
    "t0 = time()\n",
    "mdf = tf[tf.Xsex=='m']\n",
    "df = pd.DataFrame(mdf.iloc[:,:2000].mean(axis=0), columns = ['m'])\n",
    "print time()-t0\n",
    "\n",
    "# Compute mean value of each of first 2000 columns for women\n",
    "t0 = time()\n",
    "fdf = tf[tf.Xsex == 'f']\n",
    "df['f'] = fdf.iloc[:,:2000].mean(axis=0)\n",
    "print time()-t0\n",
    "\n",
    "df['diff'] = df['m']-df['f']\n",
    "\n",
    "df.sort_values('diff', inplace=True)\n",
    "\n",
    "# Save top 200 words for women and men for report\n",
    "women_list = ''\n",
    "for word in df.index[:200]:\n",
    "    women_list = women_list + word + ', '\n",
    "    \n",
    "men_list = ''\n",
    "# Write men_list in reverse order so most popular words are on top\n",
    "for i in range(-1, -200, -1):\n",
    "    men_list = men_list + df.index[i] + ', '\n",
    "    \n",
    "# order top females words by 'f' column\n",
    "df_f = df.head(10)\n",
    "df_f = df_f.sort_values('f', ascending=False)\n",
    "\n",
    "# order top male words by 'm' column\n",
    "df_m = df.tail(10)\n",
    "df_m = df_m.sort_values('m', ascending=True)\n",
    "\n",
    "# Create new df with top 10 features for men and top 10 features for women\n",
    "\n",
    "df_mf = df_f.append(df_m)\n",
    "df_mf.to_csv('../Assets/Tableau/df_mf.csv')\n",
    "\n",
    "# Compare word frequency for social drinkers vs. heavy drinkers vs. non drinkers\n",
    "\n",
    "# Compute mean value of each of first 2000 columns for social drinks\n",
    "t0 = time()\n",
    "ddf = tf[tf.Xdrinks=='socially']\n",
    "df = pd.DataFrame(ddf.iloc[:,:2000].mean(axis=0), columns = ['social'])\n",
    "print time()-t0\n",
    "\n",
    "# Compute mean value of each of first 2000 columns for non-drinkers\n",
    "t0 = time()\n",
    "ddf = tf.query(\"Xdrinks == 'rarely'|Xdrinks == 'not at all'\")\n",
    "df['non-drinker'] = ddf.iloc[:,:2000].mean(axis=0)\n",
    "print time()-t0\n",
    "\n",
    "# Compute mean value of each of first 2000 columns for heavy drinkers\n",
    "t0 = time()\n",
    "ddf = tf.query(\"Xdrinks == 'often'|Xdrinks == 'very often'|Xdrinks == 'desperately'\")\n",
    "df['heavy'] = ddf.iloc[:,:2000].mean(axis=0)\n",
    "print time()-t0\n",
    "\n",
    "df['avg'] = df.mean(axis=1)\n",
    "# Compute differences between social drinkers' values and other categories\n",
    "df['nd_diff'] = df['non-drinker'] - df['avg']\n",
    "df['h_diff'] = df['heavy'] - df['avg']\n",
    "df['s_diff'] = df['social'] - df['avg']\n",
    "\n",
    "# Save top 200 words for heavy, social, and non-drinkers for report\n",
    "# heavy drinkers:\n",
    "df.sort_values('h_diff', ascending=False, inplace=True)\n",
    "\n",
    "heavy_list = ''\n",
    "for word in df.index[:200]:\n",
    "    heavy_list = heavy_list + word + ', '\n",
    "\n",
    "# social drinkers:\n",
    "df.sort_values('s_diff', ascending=False, inplace=True)\n",
    "\n",
    "social_list = ''\n",
    "for word in df.index[:200]:\n",
    "    social_list = social_list + word + ', '\n",
    "    \n",
    "# non-drinkers:\n",
    "df.sort_values('nd_diff', ascending=False, inplace=True)\n",
    "\n",
    "non_list = ''\n",
    "for word in df.index[:200]:\n",
    "    non_list = non_list + word + ', '\n",
    "    \n",
    "# For categories with more than two labels, produce packed bubbles instead of bar charts\n",
    "\n",
    "# Save top 18 from each cat\n",
    "# non-drinkers first\n",
    "df.sort_values('nd_diff', inplace=True, ascending=False)\n",
    "nd = pd.DataFrame(df.head(18)['non-drinker'])\n",
    "nd.columns = ['tfidf']\n",
    "nd['label'] = 'non-drinker'\n",
    "\n",
    "# social drinkers\n",
    "df.sort_values('s_diff', inplace=True, ascending=False)\n",
    "sd = pd.DataFrame(df.head(18)['social'])\n",
    "sd.columns = ['tfidf']\n",
    "sd['label'] = 'social'\n",
    "\n",
    "# heavy drinkers\n",
    "df.sort_values('h_diff', inplace=True, ascending=False)\n",
    "hd = pd.DataFrame(df.head(18)['heavy'])\n",
    "hd.columns = ['tfidf']\n",
    "hd['label'] = 'heavy'\n",
    "\n",
    "df_drinks = pd.concat([nd, sd, hd], axis=0)\n",
    "\n",
    "df_drinks.to_csv('../Assets/Tableau/df_drinks.csv')\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(okc.age, 50, normed=1, facecolor='green', alpha=0.75)\n",
    "plt.axis([15, 80, 0, .1])\n",
    "plt.show\n",
    "\n",
    "# Compare under 30 to over 30\n",
    "\n",
    "def age_encoder(age):\n",
    "    if age ==0:\n",
    "        return np.nan\n",
    "    elif age < 30:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "tf.Xage = tf.Xage.apply(age_encoder)\n",
    "\n",
    "# Compare word frequency for under 30 vs. over 30\n",
    "\n",
    "# Compute mean value of each of first 2000 columns for over 30\n",
    "t0 = time()\n",
    "odf = tf[tf.Xage==1]\n",
    "df = pd.DataFrame(odf.iloc[:,:2000].mean(axis=0), columns = ['>30'])\n",
    "print time()-t0\n",
    "\n",
    "# Compute mean value of each of first 2000 columns for under 30\n",
    "ydf = tf[tf.Xage == 0]\n",
    "df['<30'] = ydf.iloc[:,:2000].mean(axis=0)\n",
    "print time()-t0\n",
    "\n",
    "df['diff'] = df['>30']-df['<30']\n",
    "df.sort_values('diff', inplace=True)\n",
    "\n",
    "# Save top 200 words for people under and over 30\n",
    "# older people:\n",
    "df.sort_values('diff', ascending=False, inplace=True)\n",
    "\n",
    "older_list = ''\n",
    "for word in df.index[:200]:\n",
    "    older_list = older_list + word + ', '\n",
    "\n",
    "# younger people\n",
    "younger_list = ''\n",
    "# Write older_list in reverse order so most popular words are on top\n",
    "for i in range(-1, -200, -1):\n",
    "    younger_list = younger_list + df.index[i] + ', '\n",
    "    \n",
    "# Create new df with top 10 features for <30 and top >30\n",
    "\n",
    "df_y = df.head(10)\n",
    "df_y = df_y.sort_values('<30', ascending=False)\n",
    "\n",
    "df_o = df.tail(10)\n",
    "df_o = df_o.sort_values('>30')\n",
    "\n",
    "df_age = pd.concat([df_y,df_o])\n",
    "df_age.to_csv('../Assets/Tableau/df_age.csv')\n",
    "\n",
    "def drug_encoder(drugs):\n",
    "    if drugs == 'never':\n",
    "        return 0\n",
    "    elif drugs == 'sometimes' or drugs == 'often':\n",
    "        return 1\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "tf.Xdrugs = tf.Xdrugs.apply(drug_encoder)\n",
    "\n",
    "# Compute mean value of each of first 2000 columns for drug users\n",
    "t0 = time()\n",
    "udf = tf[tf.Xdrugs==1]\n",
    "df = pd.DataFrame(odf.iloc[:,:2000].mean(axis=0), columns = ['users'])\n",
    "print time()-t0\n",
    "\n",
    "# Compute mean value of each of first 2000 columns for non-users\n",
    "ydf = tf[tf.Xdrugs == 0]\n",
    "df['non-users'] = ydf.iloc[:,:2000].mean(axis=0)\n",
    "print time()-t0\n",
    "\n",
    "df['diff'] = df['users']-df['non-users']\n",
    "df.sort_values('diff', inplace=True)\n",
    "\n",
    "# Save top 200 words for users and non-users\n",
    "# users:\n",
    "df.sort_values('diff', ascending=False, inplace=True)\n",
    "\n",
    "non_user_list = ''\n",
    "for word in df.index[:200]:\n",
    "    non_user_list = non_user_list + word + ', '\n",
    "\n",
    "# non-users\n",
    "user_list = ''\n",
    "# Write older_list in reverse order so most popular words are on top\n",
    "for i in range(-1, -200, -1):\n",
    "    user_list = user_list + df.index[i] + ', '\n",
    "    \n",
    "# Create new df with top 10 features for users and nonusers\n",
    "\n",
    "df_users = df.head(10)\n",
    "df_users = df_users.sort_values('users', ascending=False)\n",
    "\n",
    "df_non = df.tail(10)\n",
    "df_non = df_non.sort_values('non-users')\n",
    "\n",
    "df_drugs = pd.concat([df_users, df_non], axis=0)\n",
    "df_drugs.to_csv('../Assets/Tableau/df_drugs.csv')\n",
    "\n",
    "plt.hist(tf.Xincome[tf.Xincome != -1], 50, normed=1, facecolor='green', alpha=0.75)\n",
    "plt.show\n",
    "\n",
    "# Divide income income into <50k, 50-100k, >100k\n",
    "\n",
    "def income_encoder(income):\n",
    "    if income == -1:\n",
    "        return -1\n",
    "    elif income <= 50000:\n",
    "        return 0\n",
    "    elif income <= 100000:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "tf.Xincome = tf.Xincome.apply(income_encoder)\n",
    "\n",
    "# Compare word frequency for different income levels\n",
    "\n",
    "# Compute mean value of each of first 2000 columns for lower income\n",
    "t0 = time()\n",
    "pdf = tf[tf.Xincome==0]\n",
    "df = pd.DataFrame(pdf.iloc[:,:2000].mean(axis=0), columns = ['<50k'])\n",
    "print time()-t0\n",
    "\n",
    "# Compute mean value of each of first 2000 columns for middle income\n",
    "t0 = time()\n",
    "mdf = tf[tf.Xincome==1]\n",
    "df['50-100k'] = mdf.iloc[:,:2000].mean(axis=0)\n",
    "print time()-t0\n",
    "\n",
    "# Compute mean value of each of first 2000 columns for highest income\n",
    "t0 = time()\n",
    "rdf = tf[tf.Xincome==2]\n",
    "df['>100k'] = rdf.iloc[:,:2000].mean(axis=0)\n",
    "print time()-t0\n",
    "\n",
    "\n",
    "# Compute differences between each income category and overall average\n",
    "df['avg'] = df.mean(axis=1)\n",
    "df['r_diff'] = df['>100k'] - df['avg']\n",
    "df['p_diff'] = df['<50k'] - df['avg']\n",
    "df['m_diff'] = df['50-100k'] - df['avg']\n",
    "\n",
    "# Save lists for each income bracket\n",
    "\n",
    "df.sort_values('r_diff', ascending=False, inplace=True)\n",
    "\n",
    "rich_list = ''\n",
    "for word in df.index[:200]:\n",
    "    rich_list = rich_list + word + ', '\n",
    "    \n",
    "df.sort_values('m_diff', ascending=False, inplace=True)\n",
    "\n",
    "mid_list = ''\n",
    "for word in df.index[:200]:\n",
    "    mid_list = mid_list + word + ', '\n",
    "    \n",
    "\n",
    "df.sort_values('p_diff', ascending=False, inplace=True)    \n",
    "lower_list = ''\n",
    "for word in df.index[:200]:\n",
    "    lower_list = lower_list + word + ', '\n",
    "    \n",
    "# For categories with more than two labels, produce packed bubbles instead of bar charts\n",
    "\n",
    "# Save top 18 from each cat\n",
    "# richest first\n",
    "df.sort_values('r_diff', inplace=True, ascending=False)\n",
    "df2 = pd.DataFrame(df.head(18)['>100k'])\n",
    "df2.columns = ['tfidf']\n",
    "df2['label'] = '> 100k'\n",
    "\n",
    "# middle income\n",
    "df.sort_values('m_diff', inplace=True, ascending=False)\n",
    "df3 = pd.DataFrame(df.head(18)['50-100k'])\n",
    "df3.columns = ['tfidf']\n",
    "df3['label'] = '50 - 100k'\n",
    "\n",
    "# lower income\n",
    "df.sort_values('p_diff', inplace=True, ascending=False)\n",
    "df4 = pd.DataFrame(df.head(18)['<50k'])\n",
    "df4.columns = ['tfidf']\n",
    "df4['label'] = '< 50k'\n",
    "\n",
    "df_income = pd.concat([df2, df3, df4], axis=0)\n",
    "df_income.to_csv('../Assets/Tableau/df_income.csv')\n",
    "\n",
    "# calculate dummy columns for likes dogs and likes cats\n",
    "# will be some overlap since not mutually exclusive\n",
    "\n",
    "def mask_dogs(pets):\n",
    "    # catches 'has dogs' or 'likes dogs'\n",
    "    try:\n",
    "        if pets.find('dogs') > -1:\n",
    "            if pets.find('dislikes dogs') == -1:\n",
    "                return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "def mask_cats(pets):\n",
    "    try:\n",
    "        if pets.find('cats') > -1:\n",
    "            if pets.find('dislikes cats') == -1:\n",
    "                return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "tf['Xdogs'] = tf.Xpets.apply(mask_dogs)\n",
    "tf['Xcats'] = tf.Xpets.apply(mask_cats)\n",
    "\n",
    "# find mean scores for dog people\n",
    "\n",
    "t0 = time()\n",
    "ddf = tf[tf.Xdogs==1]\n",
    "df = pd.DataFrame(ddf.iloc[:,:2000].mean(axis=0), columns = ['dogs'])\n",
    "print time()-t0\n",
    "\n",
    "# find mean scores for cat people\n",
    "cdf = tf[tf.Xcats == 1]\n",
    "df['cats'] = cdf.iloc[:,:2000].mean(axis=0)\n",
    "print time()-t0\n",
    "\n",
    "df['diff'] = df['dogs'] - df['cats']\n",
    "df.sort_values('diff', inplace=True)\n",
    "\n",
    "# remove cat, cats, dog and dogs from this list since they don't contribute insight\n",
    "df = df.drop(['cat', 'cats', 'dog', 'dogs'], axis=0)\n",
    "\n",
    "# Save top 200 words for cats and dogs for report\n",
    "cat_list = ''\n",
    "for word in df.index[:200]:\n",
    "    cat_list = cat_list + word + ', '\n",
    "    \n",
    "dog_list = ''\n",
    "# Write dog_list in reverse order so most popular words are on top\n",
    "for i in range(-1, -200, -1):\n",
    "    dog_list = dog_list + df.index[i] + ', '\n",
    "    \n",
    "# Sort top 10 values for cats\n",
    "df_cats = df.head(10).sort_values('cats')\n",
    "\n",
    "# Sort top 10 values for dogs\n",
    "df_dogs = df.tail(10).sort_values('dogs', ascending=False)\n",
    "\n",
    "# Save df pets\n",
    "df_pets = pd.concat([df_dogs, df_cats], axis=0)\n",
    "df_pets.to_csv('../Assets/Tableau/df_ed.csv')\n",
    "\n",
    "def ed_encoder(ed):\n",
    "    # a person is a college grad if they either \"graduated from college/university\"\n",
    "    # or mention law school, med, school, masters program or ph. d program (all instances of the word program are graduate )\n",
    "    try:\n",
    "        if ed == 'graduated from college/university' or ed.find('law') >= 0 or ed.find('med') >= 0 or ed.find('program') >= 0:\n",
    "            return 1\n",
    "        # space camp answers are facetious and must be excluded\n",
    "        # BTW I am in space camp right now\n",
    "        elif ed.find('space camp') >= 0:\n",
    "            return np.nan\n",
    "        else: return 0\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "tf.Xeducation = tf.Xeducation.apply(ed_encoder)\n",
    "\n",
    "# Compare word frequency for college educated vs. not college\n",
    "\n",
    "# Compute mean value of each of first 2000 columns for college\n",
    "t0 = time()\n",
    "df2 = tf[tf.Xage==1]\n",
    "df = pd.DataFrame(df2.iloc[:,:2000].mean(axis=0), columns = ['grad'])\n",
    "print time()-t0\n",
    "\n",
    "# Compute mean value of each of first 2000 columns for under 30\n",
    "df2 = tf[tf.Xage == 0]\n",
    "df['non-grad'] = df2.iloc[:,:2000].mean(axis=0)\n",
    "print time()-t0\n",
    "\n",
    "df['diff'] = df['grad'] - df['non-grad']\n",
    "df.sort_values('diff', inplace=True)\n",
    "\n",
    "# Save top 200 words for grads and non-grads for report\n",
    "non_grad_list = ''\n",
    "for word in df.index[:200]:\n",
    "    non_grad_list = non_grad_list + word + ', '\n",
    "    \n",
    "grad_list = ''\n",
    "# Write grad_list in reverse order so most popular words are on top\n",
    "for i in range(-1, -200, -1):\n",
    "    grad_list = grad_list + df.index[i] + ', '\n",
    "\n",
    "# Sort top 10 words for non-grad\n",
    "df3 = df.head(10).sort_values('non-grad', ascending=False)\n",
    "\n",
    "# Sort top 10 words for grad\n",
    "df4 = df.tail(10).sort_values('grad')\n",
    "\n",
    "df = pd.concat([df3, df4], axis=0)\n",
    "\n",
    "df.to_csv('../Assets/Tableau/df_ed.csv')\n",
    "\n",
    "# It will be more efficient to encode dummies for each ethnic group than to search each entry\n",
    "# People who list multiple ethnicities will count for all ethnicities listed\n",
    "\n",
    "# write encoder for each ethnicity\n",
    "\n",
    "groups = ['asian', 'middle eastern', 'black', 'native american', 'indian', 'pacific islander', 'hispanic / latin', 'white']\n",
    "\n",
    "for ethnicity in groups:\n",
    "    def ethnicity_encoder(eth):\n",
    "        global ethnicity\n",
    "        try:\n",
    "            if eth.find(ethnicity) >= 0:\n",
    "                return 1\n",
    "            else: return 0\n",
    "        except:\n",
    "            return 0\n",
    "        \n",
    "    tf['X%s' %ethnicity] = tf.Xethnicity.apply(ethnicity_encoder)\n",
    "    \n",
    "df=pd.DataFrame(index=tf.columns[:2000])\n",
    "# Compute mean value of each of first 2000 columns for each ethnic group\n",
    "for ethnicity in groups:\n",
    "    t0 = time()\n",
    "    df2 = tf[tf['X%s' %ethnicity] == 1]\n",
    "    df[ethnicity] = pd.DataFrame(df2.iloc[:,:2000].mean(axis=0))\n",
    "    print time()-t0\n",
    "    \n",
    "df['avg'] = df.mean(axis=1)\n",
    "\n",
    "for ethnicity in groups:\n",
    "    df['%s_diff' %ethnicity] = df[ethnicity] - df['avg']\n",
    "    \n",
    "# List top 200 words for each ethnicity\n",
    "\n",
    "# Create an empty string assigned to each ethnicity\n",
    "eth_dic = {}\n",
    "for ethnicity in groups:\n",
    "    eth_dic[ethnicity] = ''\n",
    "\n",
    "# Fill string for each ethnicity with top words\n",
    "for ethnicity in groups:\n",
    "    df.sort_values('%s_diff' %ethnicity, ascending=False, inplace=True)\n",
    "    \n",
    "    for word in df.index[:200]:\n",
    "        eth_dic[ethnicity] = eth_dic[ethnicity] + word + ', '\n",
    "\n",
    "# There are 8 different ethnic groups available\n",
    "# Tableau does well with about 50 to 60 words for packed bubbles\n",
    "# Take top 7 words for each ethnicity\n",
    "\n",
    "# Drop words asian, middle, eastern, indian, and india as they are top ranking words but redundant with categories\n",
    "\n",
    "df.drop(['asian', 'middle', 'eastern', 'indian', 'india'], axis=0, inplace=True)\n",
    "\n",
    "# must have at least one row in dataframe in order to use pd.concat\n",
    "df_ethnicity = pd.DataFrame(index=[0], columns=['tfidf', 'label'])\n",
    "\n",
    "for ethnicity in groups:\n",
    "    # Save top 7 words for each ethnicity\n",
    "    df.sort_values('%s_diff' %ethnicity, ascending=False, inplace=True)\n",
    "    df3 = pd.DataFrame(df.head(7)[ethnicity])\n",
    "    df3.columns=['tfidf']\n",
    "    df3['label'] = ethnicity\n",
    "    \n",
    "    df_ethnicity = pd.concat([df_ethnicity, df3], axis=0)\n",
    "    \n",
    "# drop dummy row from top\n",
    "# df_ethnicity.drop(0, axis=0, inplace=True)\n",
    "\n",
    "df_ethnicity.to_csv('../Assets/Tableau/df_ethnicity.csv')\n",
    "    \n",
    "\n",
    "df = pd.DataFrame(index=tf.columns[:2000])\n",
    "df_jobs = pd.DataFrame(index=[0], columns=['tfidf', 'label'])\n",
    "job_dic = {}\n",
    "# Most popular job category is \"other\"  Exclude that\n",
    "for job in tf.Xjob.value_counts()[1:11].index:\n",
    "    # Save a column of dummies for each job category\n",
    "    def job_encoder(career):\n",
    "        global job\n",
    "        try:\n",
    "            if career.find(job) >= 0:\n",
    "                return 1\n",
    "            else: return 0\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    tf['X%s' %job] = tf.Xjob.apply(job_encoder)\n",
    "\n",
    "    # Compute mean tfidf scores for job type\n",
    "    t0 = time()\n",
    "    df2 = tf[tf['X%s' %job] == 1]\n",
    "    df[job] = pd.DataFrame(df2.iloc[:,:2000].mean(axis=0))\n",
    "    print time()-t0\n",
    "    \n",
    "# Compute overall mean tfidf scores\n",
    "df['avg'] = df.mean(axis=1)\n",
    "\n",
    "    \n",
    "for job in tf.Xjob.value_counts()[1:11].index: \n",
    "    # compute diff between scores for each job and overall mean\n",
    "    df['%s_diff' %job] = df[job] - df['avg']    \n",
    "    \n",
    "\n",
    "    # sort by job\n",
    "    # save top 200 words as dictionary values for each job\n",
    "    # save top 6 words with tfidf scores and labels to df_jobs\n",
    "    job_dic[job] = ''\n",
    "    df.sort_values('%s_diff' %job, ascending=False, inplace=True)\n",
    "    # save top 200 words to reserved string in job_dic\n",
    "    for word in df.index[:200]:\n",
    "        job_dic[job] = job_dic[job] + word + ', '\n",
    "        \n",
    "    # Save top 6 words to df_jobs\n",
    "    df.sort_values('%s_diff' %job, ascending=False, inplace=True)\n",
    "    \n",
    "    df3 = pd.DataFrame(df.head(6)[job])\n",
    "    df3.columns=['tfidf']\n",
    "    df3['label'] = job\n",
    "    \n",
    "    df_jobs = pd.concat([df_jobs, df3], axis=0)\n",
    "    \n",
    "# drop dummy row from top\n",
    "df_jobs.drop(0, axis=0, inplace=True)\n",
    "\n",
    "df_jobs.to_csv('../Assets/Tableau/df_jobs.csv')\n",
    "\n",
    "# Compute mean value of each of first 2000 columns for gay men\n",
    "\n",
    "df2 = tf[tf.Xsex=='m'][tf.Xorientation=='gay']\n",
    "df = pd.DataFrame(df2.iloc[:,:2000].mean(axis=0), columns = ['gay men'])\n",
    "\n",
    "\n",
    "# Compute mean value of each of first 2000 columns for bi men\n",
    "df2 = tf[tf.Xsex=='m'][tf.Xorientation=='bisexual']\n",
    "df['bi men'] = df2.iloc[:,:2000].mean(axis=0)\n",
    "\n",
    "\n",
    "# Compute mean values for straight men\n",
    "df2 = tf[tf.Xsex=='m'][tf.Xorientation=='straight']\n",
    "df['straight men'] = df2.iloc[:,:2000].mean(axis=0)\n",
    "\n",
    "\n",
    "# Compute mean values for gay women\n",
    "df2 = tf[tf.Xsex=='f'][tf.Xorientation=='gay']\n",
    "df['gay women'] = df2.iloc[:,:2000].mean(axis=0)\n",
    "\n",
    "# Compute mean values for bi women\n",
    "df2 = tf[tf.Xsex=='f'][tf.Xorientation=='bisexual']\n",
    "df['bi women'] = df2.iloc[:,:2000].mean(axis=0)\n",
    "\n",
    "# Compute mean values for straight women\n",
    "df2 = tf[tf.Xsex=='f'][tf.Xorientation=='straight']\n",
    "df['straight women'] = df2.iloc[:,:2000].mean(axis=0)\n",
    "\n",
    "\n",
    "df['avg'] = df.mean(axis=1)\n",
    "df['gay men diff'] = df['gay men'] - df.avg\n",
    "df['bi men diff'] = df['bi men'] - df.avg\n",
    "df['straight men diff'] = df['straight men'] - df.avg\n",
    "df['gay women diff'] = df['gay women'] - df.avg\n",
    "df['bi women diff'] = df['bi women'] - df.avg\n",
    "df['straight women diff'] = df['straight women'] - df.avg\n",
    "\n",
    "# Save word lists\n",
    "df_orientation = pd.DataFrame(index=[0], columns=['tfidf', 'label'])\n",
    "group_dic = {}\n",
    "for group in df.columns[:6]:\n",
    "    df.sort_values('%s diff' %group, ascending=False, inplace=True)\n",
    "    group_dic[group] = ''\n",
    "    for word in df.index[:200]:\n",
    "        group_dic[group] = group_dic[group] + word + ', '\n",
    "\n",
    "# Save df for Tableau with top 10 for each category\n",
    "    df2 = pd.DataFrame(df[group].head(10))\n",
    "    df2.columns = ['tfidf']\n",
    "    df2['label'] = group\n",
    "\n",
    "    \n",
    "    df_orientation = pd.concat([df_orientation, df2], axis=0)\n",
    "    \n",
    "df_orientation.drop(0, axis=0, inplace=True)\n",
    "\n",
    "df_orientation.to_csv('../Assets/Tableau/df_orientation.csv')\n",
    "\n",
    "# list religions \n",
    "religions = []\n",
    "for religion in tf.Xreligion.value_counts().index:\n",
    "    rel = religion.split(' ', 1)[0]\n",
    "    if rel not in religions:\n",
    "        religions.append(rel)\n",
    "religions = filter(lambda x: x != 'other', religions)\n",
    "\n",
    "# Encode dummies for each religion\n",
    "# rel is individual person's religion string \"Christianity and very serious about it\"\n",
    "# religion is each group \"Christianity\"\n",
    "\n",
    "tf.Xreligion.replace(np.nan, '', inplace=True)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "rel_dic = {}\n",
    "df_religion = pd.DataFrame(index=[0], columns=['tfidf', 'label'])\n",
    "\n",
    "for religion in religions:\n",
    "    tf['X%s' %religion] = tf.Xreligion.apply(lambda rel: 1 if rel.split(' ', 1)[0] == religion else 0)\n",
    "\n",
    "    # Compute mean values for each religion\n",
    "    df2 = tf[tf['X%s' %religion]==1]\n",
    "    df[religion] = df2.iloc[:,:2000].mean(axis=0)\n",
    "    \n",
    "# Compute mean for each word across religons\n",
    "df['avg'] = df.mean(axis=1)\n",
    "\n",
    "for religion in religions:\n",
    "    df['%s_diff' %religion] = df[religion] -df['avg']\n",
    "\n",
    "    # Save top 200 words for each religion as string\n",
    "    df.sort_values('%s_diff' % religion, inplace=True, ascending=False)\n",
    "    \n",
    "    rel_dic[religion] = ''\n",
    "    for word in df.index[:200]:\n",
    "        rel_dic[religion] = rel_dic[religion] + word + ', '\n",
    "    \n",
    "    # Save top 7 words for each religon as df for Tableau\n",
    "    df2 = pd.DataFrame(df[religion].head(7))\n",
    "    df2.columns = ['tfidf']\n",
    "    df2['label'] = religion\n",
    "    \n",
    "    df_religion = pd.concat([df_religion, df2], axis=0)\n",
    "    \n",
    "df_religion.drop(0, axis=0, inplace=True)\n",
    "df_religion.to_csv('../Assets/Tableau/df_religion.csv')\n",
    "    \n",
    "    \n",
    "# Encode dummies for each religion\n",
    "# rel is individual person's religion string \"Christianity and very serious about it\"\n",
    "# religion is each group \"Christianity\"\n",
    "\n",
    "tf.Xreligion.replace(np.nan, '', inplace=True)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "rel_dic = {}\n",
    "df_religion = pd.DataFrame(index=[0], columns=['tfidf', 'label'])\n",
    "\n",
    "for religion in religions:\n",
    "    tf['X%s' %religion] = tf.Xreligion.apply(lambda rel: 1 if rel.split(' ', 1)[0] == religion else 0)\n",
    "\n",
    "    # Compute mean values for each religion\n",
    "    df2 = tf[tf['X%s' %religion]==1]\n",
    "    df[religion] = df2.iloc[:,:2000].mean(axis=0)\n",
    "    \n",
    "# Compute mean for each word across religons\n",
    "df['avg'] = df.mean(axis=1)\n",
    "\n",
    "for religion in religions:\n",
    "    df['%s_diff' %religion] = df[religion] -df['avg']\n",
    "\n",
    "    # Save top 200 words for each religion as string\n",
    "    df.sort_values('%s_diff' % religion, inplace=True, ascending=False)\n",
    "    \n",
    "    rel_dic[religion] = ''\n",
    "    for word in df.index[:200]:\n",
    "        rel_dic[religion] = rel_dic[religion] + word + ', '\n",
    "    \n",
    "    # Save top 7 words for each religon as df for Tableau\n",
    "    df2 = pd.DataFrame(df[religion].head(7))\n",
    "    df2.columns = ['tfidf']\n",
    "    df2['label'] = religion\n",
    "    \n",
    "    df_religion = pd.concat([df_religion, df2], axis=0)\n",
    "    \n",
    "df_religion.drop(0, axis=0, inplace=True)\n",
    "df_religion.to_csv('../Assets/Tableau/df_religion.csv')\n",
    "\n",
    "levels = []\n",
    "for religion in tf.Xreligion.value_counts().index:\n",
    "    try:\n",
    "        level = religion.split('and ', 1)[1]\n",
    "    except: continue\n",
    "    if level not in levels:\n",
    "        levels.append(level)\n",
    "\n",
    "def level_encoder(rel):\n",
    "    try:\n",
    "        for level in levels:\n",
    "            if rel.find(level) >0:\n",
    "                return level\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "tf['Xreligiousness'] = tf.Xreligion.apply(level_encoder)\n",
    "    \n",
    "df = pd.DataFrame()\n",
    "df_religiousness = pd.DataFrame(index=[0], columns=['tfidf', 'label'])\n",
    "level_dic = {}\n",
    "for level in levels:\n",
    "    # Compute mean values for each level of religiousness\n",
    "    df2 = tf[tf['Xreligiousness']==level]\n",
    "    df[level] = df2.iloc[:,:2000].mean(axis=0)\n",
    "# Compute averages\n",
    "df['avg'] = df.mean(axis=1)\n",
    "\n",
    "for level in levels:\n",
    "    # sort by diff for each category\n",
    "    df['%s_diff' %level] = df[level] - df['avg']\n",
    "    df.sort_values('%s_diff' % level, inplace=True, ascending=False)\n",
    "    # Save top 200 to level_dic\n",
    "    level_dic[level] = ''\n",
    "    for word in df.index[:200]:\n",
    "        level_dic[level] = level_dic[level] + word + ', '\n",
    "    # Save top 20 to df\n",
    "    df2 = pd.DataFrame(df[level].head(20))\n",
    "    df2.columns = ['tfidf']\n",
    "    df2['label'] = level\n",
    "    \n",
    "    df_religiousness = pd.concat([df_religiousness, df2], axis=0)\n",
    "df_religiousness.drop(0, axis=0, inplace=True)\n",
    "\n",
    "df_religiousness.to_csv('../Assets/Tableau/df_religiousness.csv')\n",
    "\n",
    "tf.Xdiet.value_counts()\n",
    "\n",
    "# ignore anything and other\n",
    "# just look for vegetarian, vegan, kosher, halal\n",
    "\n",
    "def diet_encoder(diet):\n",
    "    try:\n",
    "        if diet.find('vegan') >= 0:\n",
    "            return 'vegan'\n",
    "        elif diet.find('vegetarian') >= 0:\n",
    "            return 'vegetarian'\n",
    "        elif diet.find('kosher') >= 0:\n",
    "            return 'kosher'\n",
    "        elif diet.find('halal') >= 0:\n",
    "            return 'halal'\n",
    "        else:\n",
    "            return ''\n",
    "    except:\n",
    "        return ''\n",
    "    \n",
    "tf.Xdiet = tf.Xdiet.apply(diet_encoder)\n",
    "\n",
    "# Exclude '' from diets\n",
    "diets = tf.Xdiet.value_counts().index[1:]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df_diet = pd.DataFrame(index=[0], columns=['tfidf', 'label'])\n",
    "diet_dic = {}\n",
    "for diet in diets:\n",
    "    # Compute mean values for each level of religiousness\n",
    "    df2 = tf[tf.Xdiet==diet]\n",
    "    df[diet] = df2.iloc[:,:2000].mean(axis=0)\n",
    "# Compute averages\n",
    "df['avg'] = df.mean(axis=1)\n",
    "\n",
    "for diet in diets:\n",
    "    # sort by diff for each category\n",
    "    df['%s_diff' %diet] = df[diet] - df['avg']\n",
    "    df.sort_values('%s_diff' % diet, inplace=True, ascending=False)\n",
    "    # Save top 200 to level_dic\n",
    "    diet_dic[diet] = ''\n",
    "    for word in df.index[:200]:\n",
    "        diet_dic[diet] = diet_dic[diet] + word + ', '\n",
    "    # Save top 20 to df\n",
    "    df2 = pd.DataFrame(df[diet].head(15))\n",
    "    df2.columns = ['tfidf']\n",
    "    df2['label'] = diet\n",
    "    \n",
    "    df_diet = pd.concat([df_diet, df2], axis=0)\n",
    "df_diet.drop(0, axis=0, inplace=True)\n",
    "\n",
    "df_diet.to_csv('../Assets/Tableau/df_diet.csv')\n",
    "\n",
    "# compare labels w/ encoders vs. labels with dummies for overall correlations\n",
    "# write script to save dicts to text file\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adjust indexing\n",
    "# tf.iloc[:,:2000] adjusted to appropriate feature length (currently 1046 but may be adjusted if I drop more titles)\n",
    "# save appropriate length as length\n",
    "# tf.iloc[:,:2000] become tf.iloc[:,:length]\n",
    "\n",
    "code = code.replace('2000', 'length')\n",
    "\n",
    "# change top_words.csv to top_faves.csv\n",
    "code = code.replace('top_words.csv', 'top_faves.csv')\n",
    "\n",
    "# remove %matplotlib inline\n",
    "code = code.replace('%matplotlib inline', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# change 'df' to 'faves' in FILENAMES ONLY to avoid saving over important files\n",
    "# e.g. df_drinks.to_csv('../Assets/Tableau/df_drinks.csv') becomes df_drinks.to_csv('../Assets/Tableau/faves_drinks.csv')\n",
    "\n",
    "# Look for any time df appears BETWEEN (Tableau/) and (.csv)\n",
    "code = re.sub('Tableau\\/df', 'Tableau/faves', code)\n",
    "\n",
    "# remove all lines that include a .drop.  Rows being dropped from tf-idf will not exist in faves.\n",
    "\n",
    "code = re.sub('\\\\n.*\\.?drop.*?\\\\n', '', code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove beginning of code prior to '# Save any features we might want to filter by to tf dataframe'\n",
    "# replace with beginning\n",
    "\n",
    "code = beginning + code.split('# Save any features we might want to filter by to tf dataframe', 1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(\"faves.py\",\"w\") #opens file with name of \"test.py\"\n",
    "\n",
    "f.write(code)\n",
    "\n",
    "f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
